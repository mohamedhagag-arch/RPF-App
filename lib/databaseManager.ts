/**
 * ğŸ—„ï¸ Database Manager - Professional Database Operations
 * 
 * Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
 * ÙŠÙˆÙØ± Ø¹Ù…Ù„ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Supabase
 */

import { getSupabaseClient } from './simpleConnectionManager'
import { TABLES } from './supabase'

// ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…
export const DATABASE_TABLES = {
  PROJECTS: {
    name: TABLES.PROJECTS,
    displayName: 'Projects',
    description: 'Main projects table',
    icon: 'ğŸ—ï¸',
    color: 'blue',
    hasSensitiveData: false
  },
  BOQ_ACTIVITIES: {
    name: TABLES.BOQ_ACTIVITIES,
    displayName: 'BOQ Activities',
    description: 'BOQ activities table',
    icon: 'ğŸ“‹',
    color: 'purple',
    hasSensitiveData: false
  },
  KPI: {
    name: TABLES.KPI,
    displayName: 'KPI Records',
    description: 'Unified KPI table',
    icon: 'ğŸ“Š',
    color: 'green',
    hasSensitiveData: false
  },
  USERS: {
    name: TABLES.USERS,
    displayName: 'Users',
    description: 'Users table',
    icon: 'ğŸ‘¥',
    color: 'orange',
    hasSensitiveData: true
  },
  DIVISIONS: {
    name: 'divisions',
    displayName: 'Divisions',
    description: 'Divisions table',
    icon: 'ğŸ¢',
    color: 'indigo',
    hasSensitiveData: false
  },
  PROJECT_TYPES: {
    name: 'project_types',
    displayName: 'Project Types',
    description: 'Project types table',
    icon: 'ğŸ“',
    color: 'pink',
    hasSensitiveData: false
  },
  CURRENCIES: {
    name: 'currencies',
    displayName: 'Currencies',
    description: 'Currencies table',
    icon: 'ğŸ’°',
    color: 'yellow',
    hasSensitiveData: false
  },
  ACTIVITIES: {
    name: 'activities',
    displayName: 'Activities Database',
    description: 'Available activities database',
    icon: 'ğŸ¯',
    color: 'teal',
    hasSensitiveData: false
  },
  COMPANY_SETTINGS: {
    name: TABLES.COMPANY_SETTINGS,
    displayName: 'Company Settings',
    description: 'Company settings table',
    icon: 'âš™ï¸',
    color: 'gray',
    hasSensitiveData: false
  }
} as const

export type TableKey = keyof typeof DATABASE_TABLES
export type TableInfo = typeof DATABASE_TABLES[TableKey]

// Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„
export interface TableStats {
  tableName: string
  totalRows: number
  lastUpdated: string | null
  estimatedSize: string
  hasData: boolean
}

// Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
export interface OperationResult {
  success: boolean
  message: string
  data?: any
  error?: string
  affectedRows?: number
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø©
 */
export function getAllTables(): TableInfo[] {
  return Object.values(DATABASE_TABLES)
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙˆÙ„ Ù…Ø­Ø¯Ø¯
 */
export function getTableInfo(tableKey: TableKey): TableInfo {
  return DATABASE_TABLES[tableKey]
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¬Ø¯ÙˆÙ„
 */
export async function getTableStats(tableName: string): Promise<TableStats | null> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“Š Getting stats for table: ${tableName}`)
    
    // Ø¹Ø¯ Ø§Ù„ØµÙÙˆÙ
    const { count, error: countError } = await supabase
      .from(tableName)
      .select('*', { count: 'exact', head: true })
    
    if (countError) {
      console.error(`âŒ Error counting rows in ${tableName}:`, countError)
      return null
    }
    
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«
    const { data: latestRow, error: latestError } = await supabase
      .from(tableName)
      .select('updated_at, created_at')
      .order('updated_at', { ascending: false, nullsFirst: false })
      .limit(1)
      .single()
    
    const lastUpdated = (latestRow as any)?.updated_at || (latestRow as any)?.created_at || null
    
    // ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø­Ø¬Ù… (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
    const estimatedSizeKB = (count || 0) * 0.5 // ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ
    const estimatedSize = estimatedSizeKB < 1024 
      ? `${estimatedSizeKB.toFixed(2)} KB`
      : `${(estimatedSizeKB / 1024).toFixed(2)} MB`
    
    const stats: TableStats = {
      tableName,
      totalRows: count || 0,
      lastUpdated,
      estimatedSize,
      hasData: (count || 0) > 0
    }
    
    console.log(`âœ… Stats for ${tableName}:`, stats)
    return stats
    
  } catch (error: any) {
    console.error(`âŒ Error getting stats for ${tableName}:`, error)
    return null
  }
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
 */
export async function getAllTablesStats(): Promise<Record<string, TableStats | null>> {
  console.log('ğŸ“Š Getting stats for all tables...')
  
  const stats: Record<string, TableStats | null> = {}
  const tables = getAllTables()
  
  // ØªØ­Ù…ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
  const promises = tables.map(async (table) => {
    const tableStats = await getTableStats(table.name)
    return { name: table.name, stats: tableStats }
  })
  
  const results = await Promise.all(promises)
  
  results.forEach(({ name, stats: tableStats }) => {
    stats[name] = tableStats
  })
  
  console.log('âœ… All tables stats loaded')
  return stats
}

/**
 * Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ø¯ÙˆÙ„ (Ø®Ø·ÙŠØ±!)
 */
export async function clearTableData(tableName: string): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ—‘ï¸ Clearing all data from table: ${tableName}`)
    
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
    const { count } = await supabase
      .from(tableName)
      .select('*', { count: 'exact', head: true })
    
    if (!count || count === 0) {
      return {
        success: true,
        message: `Table ${tableName} is already empty`,
        affectedRows: 0
      }
    }
    
    // Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    const { error } = await supabase
      .from(tableName)
      .delete()
      .neq('id', '00000000-0000-0000-0000-000000000000') // Ø­Ø°Ù ÙƒÙ„ Ø´ÙŠØ¡
    
    if (error) {
      console.error(`âŒ Error clearing ${tableName}:`, error)
      return {
        success: false,
        message: `Failed to clear table: ${error.message}`,
        error: error.message
      }
    }
    
    console.log(`âœ… Successfully cleared ${count} rows from ${tableName}`)
    return {
      success: true,
      message: `Successfully cleared ${count} rows from ${tableName}`,
      affectedRows: count
    }
    
  } catch (error: any) {
    console.error(`âŒ Error clearing table ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to clear table',
      error: error.message
    }
  }
}

/**
 * ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙˆÙ„ Ø¥Ù„Ù‰ JSON
 */
export async function exportTableData(tableName: string): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“¤ Exporting data from table: ${tableName}`)
    
    // Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pagination
    let allData: any[] = []
    let from = 0
    const limit = 1000 // Supabase max limit per request
    
    while (true) {
      const currentBatch = Math.floor(from / limit) + 1
      console.log(`ğŸ“¤ Fetching batch ${currentBatch} (rows ${from + 1} to ${from + limit})...`)
      
      const { data, error } = await supabase
        .from(tableName)
        .select('*')
        .order('created_at', { ascending: false })
        .range(from, from + limit - 1)
      
      if (error) {
        console.error(`âŒ Error exporting ${tableName}:`, error)
        return {
          success: false,
          message: `Failed to export table: ${error.message}`,
          error: error.message
        }
      }
      
      if (!data || data.length === 0) {
        console.log(`ğŸ“¤ No more data found. Total fetched: ${allData.length} rows`)
        break // No more data
      }
      
      allData = [...allData, ...data]
      console.log(`ğŸ“¤ Batch ${currentBatch} completed: ${data.length} rows (Total: ${allData.length})`)
      
      if (data.length < limit) {
        console.log(`ğŸ“¤ Last batch completed. Total exported: ${allData.length} rows`)
        break // Last page
      }
      
      from += limit
      
      // Add a small delay to prevent overwhelming the server
      if (from > 0 && from % 5000 === 0) {
        console.log(`ğŸ“¤ Processed ${from} rows, taking a short break...`)
        await new Promise(resolve => setTimeout(resolve, 100))
      }
    }
    
    console.log(`âœ… Successfully exported ${allData.length} rows from ${tableName}`)
    return {
      success: true,
      message: `Successfully exported ${allData.length} rows`,
      data: allData,
      affectedRows: allData.length
    }
    
  } catch (error: any) {
    console.error(`âŒ Error exporting table ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to export table',
      error: error.message
    }
  }
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„
 */
export async function importTableData(
  tableName: string, 
  data: any[],
  mode: 'append' | 'replace' = 'append'
): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“¥ Importing ${data.length} rows to table: ${tableName} (mode: ${mode})`)
    
    // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆØ¶Ø¹ "replace"ØŒ Ù†Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£ÙˆÙ„Ø§Ù‹
    if (mode === 'replace') {
      console.log('ğŸ—‘ï¸ Clearing existing data first...')
      const clearResult = await clearTableData(tableName)
      if (!clearResult.success) {
        return clearResult
      }
    }
    
    // Clean and validate data before importing
    const cleanedData = data.map((row, index) => {
      const cleanedRow: any = {}
      
      Object.keys(row).forEach(key => {
        let value = row[key]
        
        // Skip empty or null values
        if (value === '' || value === 'null' || value === 'NULL' || value === null || value === undefined) {
          cleanedRow[key] = null
          return
        }
        
        // Handle different data types
        if (typeof value === 'string') {
          // Try to convert date strings
          if (key.toLowerCase().includes('date') || key.toLowerCase().includes('time')) {
            // Skip if it's clearly not a date (contains letters that shouldn't be in dates)
            if (/[a-zA-Z]{3,}/.test(value) && !value.match(/^\d{4}-\d{2}-\d{2}/)) {
              console.warn(`âš ï¸ Skipping invalid date value in row ${index + 1}, column ${key}: "${value}"`)
              cleanedRow[key] = null
              return
            }
          }
        }
        
        cleanedRow[key] = value
      })
      
      // Log first few cleaned rows for debugging
      if (index < 3) {
        console.log(`ğŸ“‹ Cleaned Row ${index + 1}:`, cleanedRow)
      }
      
      return cleanedRow
    })
    
    console.log(`ğŸ“‹ Data cleaned, importing ${cleanedData.length} rows...`)
    
    // Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    const { error } = await supabase
      .from(tableName)
      .insert(cleanedData as any)
    
    if (error) {
      console.error(`âŒ Error importing to ${tableName}:`, error)
      
      // Try to provide more helpful error message
      let errorMessage = error.message
      if (error.message.includes('invalid input syntax for type timestamp')) {
        errorMessage = 'Invalid date format detected. Please check your CSV file for proper date formatting (YYYY-MM-DD) and ensure no text data is in date columns.'
      }
      
      return {
        success: false,
        message: `Failed to import data: ${errorMessage}`,
        error: error.message
      }
    }
    
    console.log(`âœ… Successfully imported ${cleanedData.length} rows to ${tableName}`)
    return {
      success: true,
      message: `Successfully imported ${cleanedData.length} rows`,
      affectedRows: cleanedData.length
    }
    
  } catch (error: any) {
    console.error(`âŒ Error importing to table ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to import data',
      error: error.message
    }
  }
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ (template) ÙØ§Ø±Øº Ù„Ù„Ø¬Ø¯ÙˆÙ„
 */
export async function getTableTemplate(tableName: string): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“‹ Getting template for table: ${tableName}`)
    
    // Ø¬Ù„Ø¨ ØµÙ ÙˆØ§Ø­Ø¯ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    const { data, error } = await supabase
      .from(tableName)
      .select('*')
      .limit(1)
    
    if (error) {
      console.error(`âŒ Error getting template for ${tableName}:`, error)
      return {
        success: false,
        message: `Failed to get template: ${error.message}`,
        error: error.message
      }
    }
    
    // Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† ÙØ§Ø±Øº Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¹ Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø©
    const template: any = {}
    if (data && data.length > 0) {
      Object.keys(data[0]).forEach(key => {
        const value = data[0][key]
        
        // Set appropriate default values based on column type
        if (value === null || value === undefined) {
          template[key] = ''
        } else if (typeof value === 'number') {
          template[key] = 0
        } else if (typeof value === 'boolean') {
          template[key] = false
        } else if ((value as any) instanceof Date || (typeof value === 'string' && /^\d{4}-\d{2}-\d{2}/.test(value))) {
          // Date fields - provide example format
          template[key] = 'YYYY-MM-DD'
        } else {
          // String fields
          template[key] = ''
        }
      })
    }
    
    console.log(`âœ… Successfully generated template for ${tableName}`)
    return {
      success: true,
      message: 'Template generated successfully',
      data: template
    }
    
  } catch (error: any) {
    console.error(`âŒ Error getting template for ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to get template',
      error: error.message
    }
  }
}

/**
 * Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
 */
/**
 * ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
 */
export async function cleanupOldData(options: {
  kpiDaysOld?: number
  boqDaysOld?: number
  projectsDaysOld?: number
} = {}): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    const {
      kpiDaysOld = 180, // 6 Ø£Ø´Ù‡Ø±
      boqDaysOld = 365, // Ø³Ù†Ø©
      projectsDaysOld = 730 // Ø³Ù†ØªÙŠÙ†
    } = options

    console.log('ğŸ§¹ Starting data cleanup...')
    
    const results: any = {
      kpi: { deleted: 0, error: null },
      boq: { deleted: 0, error: null },
      projects: { deleted: 0, error: null }
    }

    // ØªÙ†Ø¸ÙŠÙ KPIs Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    if (kpiDaysOld > 0) {
      try {
        const cutoffDate = new Date()
        cutoffDate.setDate(cutoffDate.getDate() - kpiDaysOld)
        
        const { error: kpiError, count: kpiCount } = await supabase
          .from(TABLES.KPI)
          .delete({ count: 'exact' })
          .lt('created_at', cutoffDate.toISOString())
        
        if (kpiError) {
          console.error('âŒ Error cleaning KPI data:', kpiError)
          results.kpi.error = kpiError.message
        } else {
          results.kpi.deleted = kpiCount || 0
          console.log(`âœ… Cleaned ${kpiCount || 0} old KPI records`)
        }
      } catch (error: any) {
        results.kpi.error = error.message
      }
    }

    // ØªÙ†Ø¸ÙŠÙ BOQ Activities Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…ÙƒØªÙ…Ù„Ø©)
    if (boqDaysOld > 0) {
      try {
        const cutoffDate = new Date()
        cutoffDate.setDate(cutoffDate.getDate() - boqDaysOld)
        
        const { error: boqError, count: boqCount } = await supabase
          .from(TABLES.BOQ_ACTIVITIES)
          .delete({ count: 'exact' })
          .lt('created_at', cutoffDate.toISOString())
          .eq('Status', 'Completed') // ÙÙ‚Ø· Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©
        
        if (boqError) {
          console.error('âŒ Error cleaning BOQ data:', boqError)
          results.boq.error = boqError.message
        } else {
          results.boq.deleted = boqCount || 0
          console.log(`âœ… Cleaned ${boqCount || 0} old completed BOQ activities`)
        }
      } catch (error: any) {
        results.boq.error = error.message
      }
    }

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…ÙƒØªÙ…Ù„Ø©)
    if (projectsDaysOld > 0) {
      try {
        const cutoffDate = new Date()
        cutoffDate.setDate(cutoffDate.getDate() - projectsDaysOld)
        
        const { error: projectsError, count: projectsCount } = await supabase
          .from(TABLES.PROJECTS)
          .delete({ count: 'exact' })
          .lt('created_at', cutoffDate.toISOString())
          .in('Status', ['Completed', 'Cancelled']) // ÙÙ‚Ø· Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© Ø£Ùˆ Ø§Ù„Ù…Ù„ØºÙŠØ©
        
        if (projectsError) {
          console.error('âŒ Error cleaning Projects data:', projectsError)
          results.projects.error = projectsError.message
        } else {
          results.projects.deleted = projectsCount || 0
          console.log(`âœ… Cleaned ${projectsCount || 0} old completed/cancelled projects`)
        }
      } catch (error: any) {
        results.projects.error = error.message
      }
    }

    const totalDeleted = results.kpi.deleted + results.boq.deleted + results.projects.deleted
    const hasErrors = results.kpi.error || results.boq.error || results.projects.error

    console.log(`ğŸ§¹ Cleanup completed: ${totalDeleted} records deleted`)
    
    return {
      success: !hasErrors,
      message: hasErrors 
        ? `Cleanup completed with some errors. Deleted ${totalDeleted} records.`
        : `Successfully cleaned up ${totalDeleted} old records`,
      data: results,
      affectedRows: totalDeleted,
      error: hasErrors ? 'Some operations failed' : undefined
    }

  } catch (error: any) {
    console.error('âŒ Error during cleanup:', error)
    return {
      success: false,
      message: `Cleanup failed: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø·Ø§Ø¡ ØªÙˆØµÙŠØ§Øª
 */
export async function getDataSizeAnalysis(): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log('ğŸ“Š Analyzing data size...')
    
    const tables = getAllTables()
    const analysis: any = {}
    
    for (const table of tables) {
      const { count, error } = await supabase
        .from(table.name)
        .select('*', { count: 'exact', head: true })
      
      if (error) {
        console.error(`âŒ Error counting ${table.name}:`, error)
        continue
      }
      
      const estimatedSize = (count || 0) * 0.5 // ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ
      const sizeKB = estimatedSize < 1024 ? estimatedSize : estimatedSize / 1024
      const sizeMB = sizeKB < 1024 ? sizeKB : sizeKB / 1024
      
      analysis[table.name] = {
        displayName: table.displayName,
        totalRows: count || 0,
        estimatedSize: sizeMB < 1 ? `${sizeKB.toFixed(2)} KB` : `${sizeMB.toFixed(2)} MB`,
        recommendation: getRecommendation(count || 0, table.name)
      }
    }
    
    const totalRows = Object.values(analysis).reduce((sum: number, table: any) => sum + table.totalRows, 0)
    const needsCleanup = totalRows > 10000 // Ø£ÙƒØ«Ø± Ù…Ù† 10,000 Ø³Ø¬Ù„
    
    console.log(`ğŸ“Š Analysis complete: ${totalRows} total rows`)
    
    return {
      success: true,
      message: `Analysis complete. ${totalRows} total rows across all tables.`,
      data: {
        tables: analysis,
        totalRows,
        needsCleanup,
        recommendations: getOverallRecommendations(totalRows)
      }
    }
    
  } catch (error: any) {
    console.error('âŒ Error analyzing data size:', error)
    return {
      success: false,
      message: `Analysis failed: ${error.message}`,
      error: error.message
    }
  }
}

function getRecommendation(count: number, tableName: string): string {
  if (tableName.includes('KPI') && count > 5000) {
    return 'Consider cleaning KPI records older than 6 months'
  }
  if (tableName.includes('BOQ') && count > 3000) {
    return 'Consider cleaning completed BOQ activities older than 1 year'
  }
  if (tableName.includes('Projects') && count > 1000) {
    return 'Consider archiving completed projects older than 2 years'
  }
  if (count > 10000) {
    return 'Large dataset - consider data archiving'
  }
  return 'Size is acceptable'
}

function getOverallRecommendations(totalRows: number): string[] {
  const recommendations = []
  
  if (totalRows > 20000) {
    recommendations.push('Database is very large - consider immediate cleanup')
    recommendations.push('Archive old data to improve performance')
  } else if (totalRows > 10000) {
    recommendations.push('Database is large - consider cleanup')
    recommendations.push('Monitor performance and clean old data regularly')
  } else if (totalRows > 5000) {
    recommendations.push('Database size is moderate')
    recommendations.push('Consider periodic cleanup of old records')
  } else {
    recommendations.push('Database size is optimal')
    recommendations.push('Continue regular maintenance')
  }
  
  return recommendations
}

export async function canManageDatabase(): Promise<boolean> {
  try {
    const supabase = getSupabaseClient()
    
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ
    const { data: { user }, error: userError } = await supabase.auth.getUser()
    
    if (userError || !user) {
      return false
    }
    
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø¬Ø¯ÙˆÙ„ users
    const { data: appUser, error: appUserError } = await supabase
      .from('users')
      .select('role')
      .eq('id', user.id)
      .single()
    
    if (appUserError || !appUser) {
      return false
    }
    
    // ÙÙ‚Ø· Admin ÙŠÙ…ÙƒÙ†Ù‡ Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    return (appUser as any).role === 'admin'
    
  } catch (error) {
    console.error('Error checking database permissions:', error)
    return false
  }
}

/**
 * ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ…Ù„Ù JSON
 */
export function downloadAsJSON(data: any, filename: string): void {
  const json = JSON.stringify(data, null, 2)
  const blob = new Blob([json], { type: 'application/json' })
  const url = URL.createObjectURL(blob)
  
  const link = document.createElement('a')
  link.href = url
  link.download = `${filename}_${new Date().toISOString().split('T')[0]}.json`
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  
  URL.revokeObjectURL(url)
}

/**
 * ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ…Ù„Ù CSV
 */
export function downloadAsCSV(data: any[], filename: string): void {
  if (!data || data.length === 0) {
    console.warn('No data to export')
    return
  }
  
  // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
  const headers = Object.keys(data[0])
  
  // Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ CSV
  const csvRows = [
    headers.join(','), // Ø§Ù„Ø±Ø£Ø³
    ...data.map(row => 
      headers.map(header => {
        const value = row[header]
        // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ…Ø©
        const cleaned = value?.toString().replace(/"/g, '""') || ''
        return `"${cleaned}"`
      }).join(',')
    )
  ]
  
  const csv = csvRows.join('\n')
  const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' })
  const url = URL.createObjectURL(blob)
  
  const link = document.createElement('a')
  link.href = url
  link.download = `${filename}_${new Date().toISOString().split('T')[0]}.csv`
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  
  URL.revokeObjectURL(url)
}

/**
 * ØªØ­Ù…ÙŠÙ„ template CSV ÙØ§Ø±Øº Ù…Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
 */
export function downloadCSVTemplate(template: any, filename: string): void {
  const headers = Object.keys(template)
  
  // Create template with example values
  const csvRows = [
    headers.join(','), // Headers
    headers.map(header => {
      const value = template[header]
      if (value === null || value === undefined) return ''
      
      // Add quotes if needed
      const stringValue = String(value)
      if (stringValue.includes(',') || stringValue.includes('"') || stringValue.includes('\n')) {
        return `"${stringValue.replace(/"/g, '""')}"`
      }
      return stringValue
    }).join(',') // Example row
  ]
  
  const csv = csvRows.join('\n')
  const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' })
  const url = URL.createObjectURL(blob)
  
  const link = document.createElement('a')
  link.href = url
  link.download = `${filename}_template.csv`
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  
  URL.revokeObjectURL(url)
}

/**
 * Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù JSON
 */
export function readJSONFile(file: File): Promise<any> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader()
    
    reader.onload = (e) => {
      try {
        const json = JSON.parse(e.target?.result as string)
        resolve(json)
      } catch (error) {
        reject(new Error('Invalid JSON file'))
      }
    }
    
    reader.onerror = () => reject(new Error('Failed to read file'))
    reader.readAsText(file)
  })
}

/**
 * Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV
 */
export function readCSVFile(file: File): Promise<any[]> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader()
    
    reader.onload = (e) => {
      try {
        const csv = e.target?.result as string
        
        // Improved CSV parser that handles commas in quoted fields
        const parseCSVLine = (line: string): string[] => {
          const result: string[] = []
          let current = ''
          let inQuotes = false
          
          for (let i = 0; i < line.length; i++) {
            const char = line[i]
            
            if (char === '"') {
              inQuotes = !inQuotes
            } else if (char === ',' && !inQuotes) {
              result.push(current.trim())
              current = ''
            } else {
              current += char
            }
          }
          
          result.push(current.trim())
          return result.map(field => field.replace(/^"|"$/g, ''))
        }
        
        const lines = csv.split('\n').filter(line => line.trim())
        
        if (lines.length < 2) {
          reject(new Error('CSV file is empty or invalid'))
          return
        }
        
        // Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø±Ø£Ø³
        const headers = parseCSVLine(lines[0])
        
        console.log('ğŸ“‹ CSV Headers:', headers)
        
        // Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        const data = lines.slice(1).map((line, index) => {
          const values = parseCSVLine(line)
          const row: any = {}
          
          headers.forEach((header, colIndex) => {
            let value = values[colIndex] || ''
            
            // Clean and validate data
            if (value === '' || value === 'null' || value === 'NULL') {
              row[header] = null
            } else {
              row[header] = value
            }
          })
          
          // Log first few rows for debugging
          if (index < 3) {
            console.log(`ğŸ“‹ Row ${index + 1}:`, row)
          }
          
          return row
        })
        
        console.log(`ğŸ“‹ Parsed ${data.length} rows from CSV`)
        resolve(data)
      } catch (error) {
        console.error('âŒ CSV parsing error:', error)
        reject(new Error(`Failed to parse CSV file: ${error instanceof Error ? error.message : 'Unknown error'}`))
      }
    }
    
    reader.onerror = () => reject(new Error('Failed to read file'))
    reader.readAsText(file, 'UTF-8')
  })
}

