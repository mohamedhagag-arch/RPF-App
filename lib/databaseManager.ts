/**
 * ğŸ—„ï¸ Database Manager - Professional Database Operations
 * 
 * Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
 * ÙŠÙˆÙØ± Ø¹Ù…Ù„ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Supabase
 */

import { getSupabaseClient } from './simpleConnectionManager'
import { TABLES } from './supabase'

// ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…
export const DATABASE_TABLES = {
  PROJECTS: {
    name: TABLES.PROJECTS,
    displayName: 'Projects',
    description: 'Main projects table',
    icon: 'ğŸ—ï¸',
    color: 'blue',
    hasSensitiveData: false
  },
  BOQ_ACTIVITIES: {
    name: TABLES.BOQ_ACTIVITIES,
    displayName: 'BOQ Activities',
    description: 'BOQ activities table',
    icon: 'ğŸ“‹',
    color: 'purple',
    hasSensitiveData: false
  },
  KPI: {
    name: TABLES.KPI,
    displayName: 'KPI Records',
    description: 'Unified KPI table',
    icon: 'ğŸ“Š',
    color: 'green',
    hasSensitiveData: false
  },
  USERS: {
    name: TABLES.USERS,
    displayName: 'Users',
    description: 'Users table',
    icon: 'ğŸ‘¥',
    color: 'orange',
    hasSensitiveData: true
  },
  DIVISIONS: {
    name: 'divisions',
    displayName: 'Divisions',
    description: 'Divisions table',
    icon: 'ğŸ¢',
    color: 'indigo',
    hasSensitiveData: false
  },
  PROJECT_TYPES: {
    name: 'project_types',
    displayName: 'Project Types',
    description: 'Project types table',
    icon: 'ğŸ“',
    color: 'pink',
    hasSensitiveData: false
  },
  CURRENCIES: {
    name: 'currencies',
    displayName: 'Currencies',
    description: 'Currencies table',
    icon: 'ğŸ’°',
    color: 'yellow',
    hasSensitiveData: false
  },
  ACTIVITIES: {
    name: 'activities',
    displayName: 'Activities Database',
    description: 'Available activities database',
    icon: 'ğŸ¯',
    color: 'teal',
    hasSensitiveData: false
  },
  COMPANY_SETTINGS: {
    name: TABLES.COMPANY_SETTINGS,
    displayName: 'Company Settings',
    description: 'Company settings table',
    icon: 'âš™ï¸',
    color: 'gray',
    hasSensitiveData: false
  },
  MANPOWER: {
    name: TABLES.MANPOWER,
    displayName: 'MANPOWER',
    description: 'MANPOWER data for Cost Control',
    icon: 'ğŸ‘·',
    color: 'blue',
    hasSensitiveData: false
  }
} as const

export type TableKey = keyof typeof DATABASE_TABLES
export type TableInfo = typeof DATABASE_TABLES[TableKey]

// Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„
export interface TableStats {
  tableName: string
  totalRows: number
  lastUpdated: string | null
  estimatedSize: string
  hasData: boolean
}

// Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
export interface OperationResult {
  success: boolean
  message: string
  data?: any
  error?: string
  affectedRows?: number
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø©
 */
export function getAllTables(): TableInfo[] {
  return Object.values(DATABASE_TABLES)
}

/**
 * Get all Cost Control related tables
 * @returns Array of Cost Control table info
 */
export function getAllCostControlTables(): TableInfo[] {
  // Cost Control tables: MANPOWER and future tables
  const costControlTableKeys: TableKey[] = ['MANPOWER']
  return costControlTableKeys.map(key => DATABASE_TABLES[key])
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙˆÙ„ Ù…Ø­Ø¯Ø¯
 */
export function getTableInfo(tableKey: TableKey): TableInfo {
  return DATABASE_TABLES[tableKey]
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¬Ø¯ÙˆÙ„
 */
export async function getTableStats(tableName: string): Promise<TableStats | null> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“Š Getting stats for table: ${tableName}`)
    
    // Ø¹Ø¯ Ø§Ù„ØµÙÙˆÙ
    const { count, error: countError } = await supabase
      .from(tableName)
      .select('*', { count: 'exact', head: true })
    
    if (countError) {
      console.error(`âŒ Error counting rows in ${tableName}:`, countError)
      return null
    }
    
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«
    const { data: latestRow, error: latestError } = await supabase
      .from(tableName)
      .select('updated_at, created_at')
      .order('updated_at', { ascending: false, nullsFirst: false })
      .limit(1)
      .single()
    
    const lastUpdated = (latestRow as any)?.updated_at || (latestRow as any)?.created_at || null
    
    // ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø­Ø¬Ù… (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
    const estimatedSizeKB = (count || 0) * 0.5 // ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ
    const estimatedSize = estimatedSizeKB < 1024 
      ? `${estimatedSizeKB.toFixed(2)} KB`
      : `${(estimatedSizeKB / 1024).toFixed(2)} MB`
    
    const stats: TableStats = {
      tableName,
      totalRows: count || 0,
      lastUpdated,
      estimatedSize,
      hasData: (count || 0) > 0
    }
    
    console.log(`âœ… Stats for ${tableName}:`, stats)
    return stats
    
  } catch (error: any) {
    console.error(`âŒ Error getting stats for ${tableName}:`, error)
    return null
  }
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
 */
export async function getAllTablesStats(): Promise<Record<string, TableStats | null>> {
  console.log('ğŸ“Š Getting stats for all tables...')
  
  const stats: Record<string, TableStats | null> = {}
  const tables = getAllTables()
  
  // ØªØ­Ù…ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
  const promises = tables.map(async (table) => {
    const tableStats = await getTableStats(table.name)
    return { name: table.name, stats: tableStats }
  })
  
  const results = await Promise.all(promises)
  
  results.forEach(({ name, stats: tableStats }) => {
    stats[name] = tableStats
  })
  
  console.log('âœ… All tables stats loaded')
  return stats
}

/**
 * Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ø¯ÙˆÙ„ (Ø®Ø·ÙŠØ±!)
 */
export async function clearTableData(tableName: string): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ—‘ï¸ Clearing all data from table: ${tableName}`)
    
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
    const { count } = await supabase
      .from(tableName)
      .select('*', { count: 'exact', head: true })
    
    if (!count || count === 0) {
      return {
        success: true,
        message: `Table ${tableName} is already empty`,
        affectedRows: 0
      }
    }
    
    // âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… function Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§ (Ù…Ø«Ù„ MANPOWER)
    if (tableName === 'CCD - MANPOWER') {
      type ClearManpowerResult = {
        deleted_count: number
        success: boolean
        message: string
      }
      
      console.log(`ğŸ”§ Attempting to clear ${tableName} using RPC function...`)
      
      const { data, error } = await supabase
        .rpc('clear_manpower_data')
      
      if (error) {
        console.error(`âŒ Error clearing ${tableName} via RPC function:`, error)
        console.error(`âŒ Error details:`, {
          code: error.code,
          message: error.message,
          details: error.details,
          hint: error.hint
        })
        
        // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø£Ù† Ø§Ù„Ø¯Ø§Ù„Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù†Ø¹Ø·ÙŠ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©
        if (error.code === '42883' || error.message?.includes('does not exist') || error.message?.includes('function')) {
          return {
            success: false,
            message: `Function clear_manpower_data() does not exist. Please run Database/fix-clear-manpower-function.sql in Supabase SQL Editor.`,
            error: error.message,
            affectedRows: 0
          }
        }
        
        // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
        if (error.code === '42501' || error.message?.includes('permission denied')) {
          return {
            success: false,
            message: `Permission denied. Please run Database/fix-clear-manpower-function.sql to grant proper permissions.`,
            error: error.message,
            affectedRows: 0
          }
        }
        
        // Fallback: Ù„Ø§ Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø­Ø°Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ø£Ù† RLS Ø³ÙŠÙ…Ù†Ø¹Ù‡
        return {
          success: false,
          message: `Failed to clear table via RPC function: ${error.message}. Please run Database/fix-clear-manpower-function.sql to fix this.`,
          error: error.message,
          affectedRows: 0
        }
      }
      
      const result = (data as ClearManpowerResult[] | null)?.[0]
      console.log(`âœ… Successfully cleared ${result?.deleted_count || 0} rows from ${tableName}`)
      return {
        success: result?.success ?? true,
        message: result?.message || `Successfully cleared ${tableName}`,
        affectedRows: Number(result?.deleted_count) || 0
      }
    }
    
    // âœ… Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø®Ø±Ù‰)
    // âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Batch Deletion Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© - Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ø³Ø±Ø¹Ø©
    const FETCH_BATCH_SIZE = 10000 // Ø¬Ù„Ø¨ 10,000 ØµÙ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø© (Ù…Ø¶Ø§Ø¹Ù)
    const DELETE_CHUNK_SIZE = 300 // Ø­Ø°Ù 300 ØµÙ ÙÙŠ ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© (Ø­Ø¬Ù… Ø¢Ù…Ù† Ø¬Ø¯Ø§Ù‹ - UUIDs Ø·ÙˆÙŠÙ„Ø© ØªØ¬Ø¹Ù„ URL Ø·ÙˆÙŠÙ„)
    const PARALLEL_CHUNKS = 10 // Ø¹Ø¯Ø¯ Ø§Ù„Ù€ chunks Ø§Ù„ØªÙŠ ØªÙØ­Ø°Ù Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ (Ø²ÙŠØ§Ø¯Ø© Ù„Ù„Ø³Ø±Ø¹Ø©)
    const LARGE_TABLE_THRESHOLD = 50000 // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø£ÙƒØ¨Ø± Ù…Ù† 50,000 ØµÙØŒ Ø§Ø³ØªØ®Ø¯Ù… batch deletion
    
    if (count && count > LARGE_TABLE_THRESHOLD) {
      console.log(`ğŸ“¦ Large table detected (${count} rows). Using optimized batch deletion...`)
      
      let totalDeleted = 0
      let batchNumber = 0
      const maxIterations = Math.ceil(count / DELETE_CHUNK_SIZE) + 100 // Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø³Ù„Ø§Ù…Ø©
      let iterations = 0
      let checkRemainingCounter = 0
      
      // âœ… Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø­Ø°Ù Ø­ØªÙ‰ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      while (iterations < maxIterations) {
        iterations++
        batchNumber++
        checkRemainingCounter++
        
        // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙƒÙ„ 10 batches ÙÙ‚Ø· (Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©)
        if (checkRemainingCounter >= 10) {
          checkRemainingCounter = 0
          const { count: remainingCount } = await supabase
            .from(tableName)
            .select('*', { count: 'exact', head: true })
          
          if (!remainingCount || remainingCount === 0) {
            console.log(`âœ… No more rows to delete. All data cleared!`)
            break
          }
          
          console.log(`ğŸ“Š Progress: ${totalDeleted}/${count} deleted, ${remainingCount} remaining...`)
        }
        
        console.log(`ğŸ—‘ï¸ Processing batch ${batchNumber} (${totalDeleted}/${count} deleted)...`)
        
        // Ø¬Ù„Ø¨ batch Ù…Ù† IDs Ù„Ù„Ø­Ø°Ù
        const { data: batchData, error: fetchError } = await supabase
          .from(tableName)
          .select('id')
          .limit(FETCH_BATCH_SIZE)
        
        if (fetchError) {
          console.error(`âŒ Error fetching batch for deletion:`, fetchError)
          return {
            success: false,
            message: `Failed to fetch batch for deletion: ${fetchError.message}`,
            error: fetchError.message,
            affectedRows: totalDeleted
          }
        }
        
        if (!batchData || batchData.length === 0) {
          console.log(`âœ… No more rows found. All data cleared!`)
          break
        }
        
        // Ø­Ø°Ù Ø§Ù„Ù€ batch
        const idsToDelete = (batchData as Array<{ id: string }>)
          .map(row => row.id)
          .filter(Boolean) as string[]
        
        if (idsToDelete.length > 0) {
          // âœ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù€ IDs Ø¥Ù„Ù‰ chunks Ø£ØµØºØ±
          const chunks: string[][] = []
          for (let i = 0; i < idsToDelete.length; i += DELETE_CHUNK_SIZE) {
            chunks.push(idsToDelete.slice(i, i + DELETE_CHUNK_SIZE))
          }
          
          console.log(`   ğŸ“¦ Deleting ${idsToDelete.length} rows in ${chunks.length} chunks (parallel: ${PARALLEL_CHUNKS})...`)
          
          // âœ… Ø­Ø°Ù Ø§Ù„Ù€ chunks Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ (Ù„ÙƒÙ† Ø¨Ø­Ø°Ø±)
          for (let chunkGroupIndex = 0; chunkGroupIndex < chunks.length; chunkGroupIndex += PARALLEL_CHUNKS) {
            const chunkGroup = chunks.slice(chunkGroupIndex, chunkGroupIndex + PARALLEL_CHUNKS)
            
            // Ø­Ø°Ù Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù€ chunks Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ
            const deletePromises = chunkGroup.map(async (chunk, index) => {
              const chunkIndex = chunkGroupIndex + index
              const { error: deleteError } = await supabase
                .from(tableName)
                .delete()
                .in('id', chunk)
              
              if (deleteError) {
                throw { error: deleteError, chunkIndex: chunkIndex + 1, totalChunks: chunks.length }
              }
              
              return chunk.length
            })
            
            try {
              const deletedCounts = await Promise.all(deletePromises)
              const groupTotal = deletedCounts.reduce((sum, count) => sum + count, 0)
              totalDeleted += groupTotal
              
              console.log(`   âœ… Chunks ${chunkGroupIndex + 1}-${Math.min(chunkGroupIndex + PARALLEL_CHUNKS, chunks.length)}/${chunks.length} deleted: ${groupTotal} rows (Total: ${totalDeleted}/${count})`)
            } catch (err: any) {
              const errorInfo = err as { error: any, chunkIndex: number, totalChunks: number }
              console.error(`âŒ Error deleting chunk ${errorInfo.chunkIndex}/${errorInfo.totalChunks} of batch ${batchNumber}:`, errorInfo.error)
              
              // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ timeoutØŒ Ù†Ø¹Ø·ÙŠ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©
              if (errorInfo.error.message?.includes('timeout') || errorInfo.error.message?.includes('statement timeout')) {
                return {
                  success: false,
                  message: `Timeout while deleting batch ${batchNumber}, chunk ${errorInfo.chunkIndex}. ${totalDeleted} rows deleted so far. Please try again or contact support.`,
                  error: errorInfo.error.message,
                  affectedRows: totalDeleted
                }
              }
              
              return {
                success: false,
                message: `Failed to delete batch ${batchNumber}, chunk ${errorInfo.chunkIndex}: ${errorInfo.error.message}`,
                error: errorInfo.error.message,
                affectedRows: totalDeleted
              }
            }
            
            // ØªØ£Ø®ÙŠØ± ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ Ø¨ÙŠÙ† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ù€ chunks
            if (chunkGroupIndex + PARALLEL_CHUNKS < chunks.length) {
              await new Promise(resolve => setTimeout(resolve, 10))
            }
          }
          
          console.log(`âœ… Batch ${batchNumber} completed: ${idsToDelete.length} rows deleted (Total: ${totalDeleted}/${count})`)
        }
        
        // ØªØ£Ø®ÙŠØ± ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ Ø¨ÙŠÙ† Ø§Ù„Ù€ batches
        await new Promise(resolve => setTimeout(resolve, 50))
      }
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
      const { count: finalCount } = await supabase
        .from(tableName)
        .select('*', { count: 'exact', head: true })
      
      console.log(`âœ… Successfully cleared ${totalDeleted} rows from ${tableName} using batch deletion. Remaining: ${finalCount || 0}`)
      return {
        success: true,
        message: `Successfully cleared ${totalDeleted} rows from ${tableName} (deleted in ${batchNumber} batches). ${finalCount || 0} rows remaining.`,
        affectedRows: totalDeleted
      }
    } else {
      // Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØµØºÙŠØ±Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø°Ù Ø§Ù„Ø¹Ø§Ø¯ÙŠ
      const { error } = await supabase
        .from(tableName)
        .delete()
        .neq('id', '00000000-0000-0000-0000-000000000000') // Ø­Ø°Ù ÙƒÙ„ Ø´ÙŠØ¡
      
      if (error) {
        console.error(`âŒ Error clearing ${tableName}:`, error)
        
        // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ timeoutØŒ Ù†Ø¹Ø·ÙŠ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©
        if (error.message?.includes('timeout') || error.message?.includes('statement timeout')) {
          return {
            success: false,
            message: `Statement timeout. The table is too large for single operation. Please try again - the system will automatically use batch deletion.`,
            error: error.message
          }
        }
        
        return {
          success: false,
          message: `Failed to clear table: ${error.message}`,
          error: error.message
        }
      }
      
      console.log(`âœ… Successfully cleared ${count} rows from ${tableName}`)
      return {
        success: true,
        message: `Successfully cleared ${count} rows from ${tableName}`,
        affectedRows: count
      }
    }
    
  } catch (error: any) {
    console.error(`âŒ Error clearing table ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to clear table',
      error: error.message
    }
  }
}

/**
 * ØªØµØ¯ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙˆÙ„ Ø¥Ù„Ù‰ JSON
 */
export async function exportTableData(tableName: string): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
    
    console.log(`ğŸ“¤ Exporting data from table: ${tableName}`)
    if (supabaseUrl && !supabaseUrl.includes('localhost') && !supabaseUrl.includes('127.0.0.1')) {
      console.log(`   âœ… Source: Production database (${supabaseUrl.substring(0, 30)}...)`)
    }
    
    // Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pagination
    let allData: any[] = []
    let from = 0
    const limit = 1000 // Supabase max limit per request
    
    // Try to get first row to check table structure
    const { data: sampleData, error: sampleError } = await supabase
      .from(tableName)
      .select('*')
      .limit(1)
    
    if (sampleError) {
      console.error(`âŒ Error accessing table ${tableName}:`, sampleError)
      return {
        success: false,
        message: `Failed to access table: ${sampleError.message}`,
        error: sampleError.message
      }
    }
    
    // Check if table has created_at column
    const hasCreatedAt = sampleData && sampleData.length > 0 && (sampleData[0] as any)?.created_at !== undefined
    const hasId = sampleData && sampleData.length > 0 && (sampleData[0] as any)?.id !== undefined
    
    console.log(`ğŸ“¤ Table structure: ${hasCreatedAt ? 'has created_at' : hasId ? 'has id' : 'no ordering column'}`)
    
    while (true) {
      const currentBatch = Math.floor(from / limit) + 1
      console.log(`ğŸ“¤ Fetching batch ${currentBatch} (rows ${from + 1} to ${from + limit})...`)
      
      let query = supabase
        .from(tableName)
        .select('*')
        .range(from, from + limit - 1)
      
      // Only add order if column exists
      if (hasCreatedAt) {
        query = query.order('created_at', { ascending: false })
      } else if (hasId) {
        query = query.order('id', { ascending: false })
      }
      
      const { data, error } = await query
      
      if (error) {
        console.error(`âŒ Error exporting ${tableName}:`, error)
        return {
          success: false,
          message: `Failed to export table: ${error.message}`,
          error: error.message
        }
      }
      
      if (!data || data.length === 0) {
        console.log(`ğŸ“¤ No more data found. Total fetched: ${allData.length} rows`)
        break // No more data
      }
      
      allData = [...allData, ...data]
      console.log(`ğŸ“¤ Batch ${currentBatch} completed: ${data.length} rows (Total: ${allData.length})`)
      
      if (data.length < limit) {
        console.log(`ğŸ“¤ Last batch completed. Total exported: ${allData.length} rows`)
        break // Last page
      }
      
      from += limit
      
      // Add a small delay to prevent overwhelming the server
      if (from > 0 && from % 5000 === 0) {
        console.log(`ğŸ“¤ Processed ${from} rows, taking a short break...`)
        await new Promise(resolve => setTimeout(resolve, 100))
      }
    }
    
    console.log(`âœ… Successfully exported ${allData.length} rows from ${tableName}`)
    return {
      success: true,
      message: `Successfully exported ${allData.length} rows`,
      data: allData,
      affectedRows: allData.length
    }
    
  } catch (error: any) {
    console.error(`âŒ Error exporting table ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to export table',
      error: error.message
    }
  }
}

/**
 * ğŸ”— Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ±Ø§Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Foreign Key Validation)
 */
async function validateDataRelationships(tableName: string, data: any[]): Promise<{
  valid: boolean
  errors: string[]
  warnings: string[]
}> {
  const errors: string[] = []
  const warnings: string[] = []
  const supabase = getSupabaseClient()
  
  try {
    console.log(`ğŸ” Validating relationships for ${tableName}...`)
    
    // âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† BOQ Activities â†’ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Project Full Code Ù…ÙˆØ¬ÙˆØ¯
    if (tableName === TABLES.BOQ_ACTIVITIES) {
      // âœ… Priority: Check Project Full Code first (most accurate)
      const projectFullCodesSet = new Set(data.map(row => 
        row['Project Full Code'] || row['project_full_code'] || 
        (row['Project Code'] && row['Project Sub Code'] ? `${row['Project Code']}-${row['Project Sub Code']}` : null) ||
        (row['project_code'] && row['project_sub_code'] ? `${row['project_code']}-${row['project_sub_code']}` : null)
      ).filter(Boolean))
      const projectFullCodes = Array.from(projectFullCodesSet) as string[]
      
      if (projectFullCodes.length > 0) {
        const { data: existingProjects } = await supabase
          .from(TABLES.PROJECTS)
          .select('"Project Full Code", "Project Code", "Project Sub-Code"')
          .or(projectFullCodes.map(code => `"Project Full Code".eq.${code}`).join(','))
        
        const existingFullCodes = new Set((existingProjects || []).map((p: any) => 
          p['Project Full Code'] || (p['Project Code'] && p['Project Sub-Code'] ? `${p['Project Code']}-${p['Project Sub-Code']}` : null)
        ).filter(Boolean))
        const missingCodes = projectFullCodes.filter((code: string) => !existingFullCodes.has(code))
        
        if (missingCodes.length > 0) {
          warnings.push(`âš ï¸ Warning: ${missingCodes.length} BOQ activities reference non-existent projects (by Project Full Code): ${missingCodes.slice(0, 3).join(', ')}${missingCodes.length > 3 ? '...' : ''}`)
          console.warn(`âš ï¸ Missing project full codes:`, missingCodes)
        } else {
          console.log(`âœ… All ${projectFullCodes.length} project full codes exist`)
        }
      }
    }
    
    // âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† KPI â†’ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Project Full Code Ùˆ Activity Name Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ†
    if (tableName === TABLES.KPI) {
      // âœ… Priority: Use Project Full Code (most accurate matching)
      const projectFullCodesSet = new Set(data.map(row => 
        row['Project Full Code'] || row['project_full_code'] ||
        (row['Project Code'] && row['Project Sub Code'] ? `${row['Project Code']}-${row['Project Sub Code']}` : null) ||
        (row['project_code'] && row['project_sub_code'] ? `${row['project_code']}-${row['project_sub_code']}` : null)
      ).filter(Boolean))
      const projectFullCodes = Array.from(projectFullCodesSet) as string[]
      
      if (projectFullCodes.length > 0) {
        const { data: existingProjects } = await supabase
          .from(TABLES.PROJECTS)
          .select('"Project Full Code", "Project Code", "Project Sub-Code"')
          .or(projectFullCodes.map(code => `"Project Full Code".eq.${code}`).join(','))
        
        const existingFullCodes = new Set((existingProjects || []).map((p: any) => 
          p['Project Full Code'] || (p['Project Code'] && p['Project Sub-Code'] ? `${p['Project Code']}-${p['Project Sub-Code']}` : null)
        ).filter(Boolean))
        const missingCodes = projectFullCodes.filter((code: string) => !existingFullCodes.has(code))
        
        if (missingCodes.length > 0) {
          warnings.push(`âš ï¸ Warning: ${missingCodes.length} KPI records reference non-existent projects (by Project Full Code)`)
          console.warn(`âš ï¸ Missing project full codes in KPI:`, missingCodes.slice(0, 5))
        } else {
          console.log(`âœ… All ${projectFullCodes.length} project full codes exist`)
        }
      }
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Activity Names
      const activityNamesSet = new Set(data.map(row => 
        row['Activity Name'] || row['activity_name']
      ).filter((x): x is string => Boolean(x)))
      const activityNames = Array.from(activityNamesSet)
      
      if (activityNames.length > 0) {
        const { data: existingActivities } = await supabase
          .from(TABLES.BOQ_ACTIVITIES)
          .select('"Activity Name"')
        
        const existingNames = new Set((existingActivities || []).map((a: any) => a['Activity Name'] as string))
        const missingNames = activityNames.filter(name => !existingNames.has(name))
        
        if (missingNames.length > 0) {
          warnings.push(`âš ï¸ Warning: ${missingNames.length} KPI records reference non-existent activities`)
          console.warn(`âš ï¸ Missing activity names:`, missingNames.slice(0, 5))
        } else {
          console.log(`âœ… All ${activityNames.length} activity names exist`)
        }
      }
    }
    
    return {
      valid: errors.length === 0,
      errors,
      warnings
    }
    
  } catch (error: any) {
    console.error('âŒ Error validating relationships:', error)
    return {
      valid: true, // Don't block import on validation errors
      errors: [],
      warnings: [`âš ï¸ Could not validate relationships: ${error.message}`]
    }
  }
}

/**
 * ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª (Trigger Refresh)
 */
function triggerGlobalRefresh(tableName: string): void {
  console.log(`ğŸ”„ Triggering global refresh for ${tableName}...`)
  
  // Ø¥Ø±Ø³Ø§Ù„ custom event Ù„Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
  const event = new CustomEvent('database-updated', {
    detail: { tableName, timestamp: Date.now() }
  })
  window.dispatchEvent(event)
  
  console.log(`âœ… Global refresh event dispatched for ${tableName}`)
}

/**
 * ğŸ“‹ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù„Ø¬Ø¯ÙˆÙ„ (Ù…ÙˆØ­Ø¯Ø© Ù…Ø¹ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰)
 */
function getCorrectColumnNames(tableName: string): string[] {
  const columnMappings: Record<string, string[]> = {
    [TABLES.PROJECTS]: [
      'Project Code',
      'Project Sub-Code',
      'Project Full Code', // âœ… Added: Important for matching with BOQ and KPI
      'Project Name',
      'Project Type',
      'Responsible Division',
      'Plot Number',
      'KPI Completed',
      'Project Status',
      'Contract Amount',
      'Contract Status',
      'Work Programme',
      'Latitude',
      'Longitude',
      'Project Manager Email',
      'Area Manager Email',
      'Date Project Awarded',
      'Workmanship only?',
      'Advnace Payment Required',
      'Client Name',
      'Consultant Name',
      'First Party name',
      'Virtual Material Value',
      'Project Start Date',
      'Project Completion Date',
      'Project Duration',
      'Division Head Email',
      'Retention after Completion',
      'Retention after 6 Month',
      'Retention after 12 Month'
    ],
    [TABLES.BOQ_ACTIVITIES]: [
      // âœ… Basic Information (Required for Import)
      'Project Code',
      'Project Sub Code',
      'Project Full Code',
      'Activity',
      'Activity Name',
      'Activity Division',
      'Unit',
      'Zone Ref',
      'Zone Number',
      
      // âœ… Quantities (User Input)
      'Total Units',
      'Planned Units',
      'Rate',
      'Total Value',
      
      // âœ… Dates (User Input)
      'Planned Activity Start Date',
      'Deadline',
      'Calendar Duration',
      
      // âœ… Project Info (User Input)
      'Project Full Name',
      'Project Status',
      
      // âŒ Calculated Fields (Auto-Generated - NOT in Template)
      // 'Actual Units', // Calculated from KPI Actual entries
      // 'Difference', // Calculated: Actual - Planned
      // 'Variance Units', // Calculated: Total - Actual
      // 'Activity Progress %', // Calculated: (Actual/Planned) * 100
      // 'Productivity Daily Rate', // Calculated: Planned Units / Duration
      // 'Total Drilling Meters', // Calculated from KPI
      // 'Drilled Meters Planned Progress', // Calculated from KPI
      // 'Drilled Meters Actual Progress', // Calculated from KPI
      // 'Remaining Meters', // Calculated: Total - Actual
      // 'Activity Planned Status', // Calculated based on dates
      // 'Activity Actual Status', // Calculated from KPI
      // 'Reported on Data Date', // Calculated from KPI
      // 'Planned Value', // Calculated: Planned Units * Rate
      // 'Earned Value', // Calculated from KPI
      // 'Delay %', // Calculated from dates
      // 'Planned Progress %', // Calculated from dates
      // 'Activity Planned Start Date', // Calculated from Planned Activity Start Date
      // 'Activity Planned Completion Date', // Calculated from Deadline
      // 'Activity Delayed?', // Calculated from dates
      // 'Activity On Track?', // Calculated from progress
      // 'Activity Completed?', // Calculated from progress
      // 'Remaining Work Value', // Calculated: Total Value - Earned Value
      // 'Variance Works Value', // Calculated: Planned Value - Earned Value
      // 'Lookahead Start Date', // Calculated from dates
      // 'Lookahead Activity Completion Date', // Calculated from dates
      // 'Remaining Lookahead Duration for Activity Completion' // Calculated from dates
    ],
    [TABLES.KPI]: [
      // âœ… Basic Information (Required for Import)
      'Project Full Code',
      'Project Code',
      'Project Sub Code',
      'Activity Name',
      'Activity',
      'Input Type',
      
      // âœ… Quantities (User Input)
      'Quantity',
      'Unit',
      'Section',
      'Zone',
      'Drilled Meters',
      'Value',
      
      // âœ… Dates (User Input)
      'Activity Date',
      'Day',
      
      // âœ… Metadata (User Input)
      'Recorded By',
      'Notes'
      
      // âŒ Calculated Fields (Auto-Generated - NOT in Template)
      // These are calculated automatically by the system
    ]
  }
  
  return columnMappings[tableName] || []
}

/**
 * ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ CSV
 */
function convertToCSV(data: any[]): string {
  if (!data || data.length === 0) return ''
  
  const headers = Object.keys(data[0])
  const csvRows = []
  
  // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
  csvRows.push(headers.map(header => `"${header}"`).join(','))
  
  // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  data.forEach(row => {
    const values = headers.map(header => {
      const value = row[header] || ''
      return `"${value}"`
    })
    csvRows.push(values.join(','))
  })
  
  return csvRows.join('\n')
}

/**
 * ğŸ“¥ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù„Ø¨ CSV ØµØ­ÙŠØ­ Ù„Ù„Ø¬Ø¯ÙˆÙ„
 */
export async function createCorrectTemplate(tableName: string): Promise<OperationResult> {
  try {
    const correctColumns = getCorrectColumnNames(tableName)
    
    if (correctColumns.length === 0) {
      return {
        success: false,
        message: `No column mapping found for table: ${tableName}`,
        error: 'Unknown table'
      }
    }
    
    // Ø¥Ù†Ø´Ø§Ø¡ ØµÙ ÙØ§Ø±Øº Ù…Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
    const templateData = [correctColumns.reduce((acc, col) => {
      acc[col] = ''
      return acc
    }, {} as any)]
    
    // ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ CSV
    const csvContent = convertToCSV(templateData)
    
    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
    const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8;' })
    const link = document.createElement('a')
    const url = URL.createObjectURL(blob)
    link.setAttribute('href', url)
    link.setAttribute('download', `${tableName}_template.csv`)
    link.style.visibility = 'hidden'
    document.body.appendChild(link)
    link.click()
    document.body.removeChild(link)
    
    console.log(`âœ… Template created for ${tableName} with ${correctColumns.length} columns`)
    
    return {
      success: true,
      message: `Template created successfully with correct column names`,
      data: { columns: correctColumns }
    }
    
  } catch (error: any) {
    console.error('âŒ Error creating template:', error)
    return {
      success: false,
      message: `Failed to create template: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† CSV Ø¥Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
 */
function normalizeColumnNames(data: any[], tableName: string): any[] {
  console.log(`ğŸ”„ Normalizing column names for table: ${tableName}`)
  
  // Ø®Ø±ÙŠØ·Ø© ØªØ­ÙˆÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ù…ÙˆØ­Ø¯Ø© Ù…Ø¹ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰)
  const columnMappings: Record<string, Record<string, string>> = {
    [TABLES.PROJECTS]: {
      'contract_amount': 'Contract Amount',
      'project_code': 'Project Code',
      'project_name': 'Project Name',
      'project_type': 'Project Type',
      'project_status': 'Project Status',
      'client_name': 'Client Name',
      'consultant_name': 'Consultant Name',
      'project_manager_email': 'Project Manager Email',
      'area_manager_email': 'Area Manager Email',
      'date_project_awarded': 'Date Project Awarded',
      'workmanship_only': 'Workmanship only?',
      'advance_payment_required': 'Advnace Payment Required',
      'first_party_name': 'First Party name',
      'virtual_material_value': 'Virtual Material Value',
      'responsible_division': 'Responsible Division',
      'plot_number': 'Plot Number',
      'kpi_completed': 'KPI Completed',
      'contract_status': 'Contract Status',
      'work_programme': 'Work Programme',
      'latitude': 'Latitude',
      'longitude': 'Longitude'
    },
    [TABLES.BOQ_ACTIVITIES]: {
      'project_code': 'Project Code',
      'project_sub_code': 'Project Sub Code',
      'project_full_code': 'Project Full Code',
      'activity': 'Activity',
      'activity_name': 'Activity Name',
      'activity_division': 'Activity Division',
      'unit': 'Unit',
      'zone_ref': 'Zone Ref',
      'zone_number': 'Zone Number',
      'total_units': 'Total Units',
      'planned_units': 'Planned Units',
      'actual_units': 'Actual Units',
      'difference': 'Difference',
      'variance_units': 'Variance Units',
      'rate': 'Rate',
      'total_value': 'Total Value',
      'planned_value': 'Planned Value',
      'planned_activity_start_date': 'Planned Activity Start Date',
      'deadline': 'Deadline',
      'calendar_duration': 'Calendar Duration',
      'activity_progress_percentage': 'Activity Progress %',
      'productivity_daily_rate': 'Productivity Daily Rate',
      'total_drilling_meters': 'Total Drilling Meters',
      'drilled_meters_planned_progress': 'Drilled Meters Planned Progress',
      'drilled_meters_actual_progress': 'Drilled Meters Actual Progress',
      'remaining_meters': 'Remaining Meters',
      'activity_planned_status': 'Activity Planned Status',
      'activity_actual_status': 'Activity Actual Status',
      'reported_on_data_date': 'Reported on Data Date',
      'earned_value': 'Earned Value',
      'delay_percentage': 'Delay %',
      'planned_progress_percentage': 'Planned Progress %',
      'activity_planned_start_date': 'Activity Planned Start Date',
      'activity_planned_completion_date': 'Activity Planned Completion Date',
      'activity_delayed': 'Activity Delayed?',
      'activity_on_track': 'Activity On Track?',
      'activity_completed': 'Activity Completed?',
      'project_full_name': 'Project Full Name',
      'project_status': 'Project Status',
      'remaining_work_value': 'Remaining Work Value',
      'variance_works_value': 'Variance Works Value',
      'lookahead_start_date': 'Lookahead Start Date',
      'lookahead_activity_completion_date': 'Lookahead Activity Completion Date',
      'remaining_lookahead_duration_for_activity_completion': 'Remaining Lookahead Duration for Activity Completion'
    },
    [TABLES.KPI]: {
      'project_full_code': 'Project Full Code',
      'project_code': 'Project Code',
      'project_sub_code': 'Project Sub Code',
      'activity_name': 'Activity Name',
      'activity': 'Activity',
      'input_type': 'Input Type',
      'quantity': 'Quantity',
      'unit': 'Unit',
      'section': 'Section',
      'zone': 'Zone',
      'drilled_meters': 'Drilled Meters',
      'value': 'Value',
      'activity_date': 'Activity Date',
      'day': 'Day',
      'recorded_by': 'Recorded By',
      'notes': 'Notes'
    },
    [TABLES.MANPOWER]: {
      // âœ… ØªØ­ÙˆÙŠÙ„ "Column 1" Ø¥Ù„Ù‰ "Date"
      'column 1': 'Date',
      'Column 1': 'Date',
      'column_1': 'Date',
      'Column1': 'Date',
      'date': 'Date',
      'Date': 'Date',
      'project code': 'PROJECT CODE',
      'Project Code': 'PROJECT CODE',
      'project_code': 'PROJECT CODE',
      'labour code': 'LABOUR CODE',
      'Labour Code': 'LABOUR CODE',
      'labour_code': 'LABOUR CODE',
      'designation': 'Designation',
      'start': 'START',
      'finish': 'FINISH',
      'overtime': 'OVERTIME',
      'total hours': 'Total Hours',
      'Total Hours': 'Total Hours',
      'total_hours': 'Total Hours',
      'cost': 'Cost'
    }
  }
  
  const mappings = columnMappings[tableName] || {}
  
  return data.map((row, index) => {
    const normalizedRow: any = {}
    
    Object.keys(row).forEach(originalKey => {
      let value = row[originalKey]
      let normalizedKey = originalKey
      
      // âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø¬Ø¯ÙˆÙ„ MANPOWER: ØªØ­ÙˆÙŠÙ„ "Column 1" Ø¥Ù„Ù‰ "Date" Ø£ÙˆÙ„Ø§Ù‹
      if (tableName === TABLES.MANPOWER || tableName === 'CCD - MANPOWER') {
        if (originalKey === 'Column 1' || originalKey === 'column 1' || originalKey === 'Column1' || originalKey === 'column_1') {
          normalizedKey = 'Date'
        }
      }
      
      // âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø®Ø±ÙŠØ·Ø©
      if (normalizedKey === originalKey && mappings[originalKey.toLowerCase()]) {
        normalizedKey = mappings[originalKey.toLowerCase()]
      } else if (normalizedKey === originalKey && mappings[originalKey]) {
        normalizedKey = mappings[originalKey]
      }
      
      // Handle different data types
      if (typeof value === 'string') {
        // Try to convert date strings
        if (normalizedKey.toLowerCase().includes('date') || normalizedKey.toLowerCase().includes('time')) {
          // Skip if it's clearly not a date (contains letters that shouldn't be in dates)
          if (/[a-zA-Z]{3,}/.test(value) && !value.match(/^\d{4}-\d{2}-\d{2}/)) {
            console.warn(`âš ï¸ Skipping invalid date value in row ${index + 1}, column ${normalizedKey}: "${value}"`)
            normalizedRow[normalizedKey] = null
            return
          }
        }
      }
      
      normalizedRow[normalizedKey] = value
    })
    
    // Log first few normalized rows for debugging
    if (index < 3) {
      console.log(`ğŸ“‹ Normalized Row ${index + 1}:`, normalizedRow)
    }
    
    return normalizedRow
  })
}

/**
 * ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø¨Ø¹Ø¯ Ø§Ø³ØªÙŠØ±Ø§Ø¯ BOQ Activities
 */
async function runCalculationsAfterBOQImport(importedData: any[]): Promise<void> {
  try {
    const supabase = getSupabaseClient()
    const { mapBOQFromDB } = await import('./dataMappers')
    const { autoSaveActivityCalculations, updateProjectCalculations } = await import('./autoCalculationSaver')
    
    console.log(`ğŸ“Š Processing ${importedData.length} imported BOQ activities for calculations...`)
    
    const processedProjects = new Set<string>()
    
    // Process each imported activity
    for (const row of importedData) {
      try {
        // Check if row already has an ID (from insert with .select())
        let dbActivity = row
        
        // If no ID, fetch from database using Project Code and Activity Name
        if (!row.id) {
          const projectCode = row['Project Code'] || row['project_code'] || row.project_code || ''
          const activityName = row['Activity Name'] || row['Activity'] || row['activity_name'] || row.activity_name || ''
          
          if (!projectCode || !activityName) {
            console.warn('âš ï¸ Skipping activity without Project Code or Activity Name:', { projectCode, activityName })
            continue
          }
          
          // Fetch the activity from database (now it has an ID)
          const { data: fetchedActivity, error: fetchError } = await supabase
            .from(TABLES.BOQ_ACTIVITIES)
            .select('*')
            .eq('Project Code', projectCode)
            .eq('Activity Name', activityName)
            .order('created_at', { ascending: false })
            .limit(1)
            .single()
          
          if (fetchError || !fetchedActivity) {
            console.warn(`âš ï¸ Could not fetch activity ${activityName} for project ${projectCode}:`, fetchError)
            continue
          }
          
          dbActivity = fetchedActivity
        }
        
        // Map to application format
        const activity = mapBOQFromDB(dbActivity)
        
        if (!activity || !activity.id) {
          console.warn('âš ï¸ Skipping activity without ID:', dbActivity)
          continue
        }
        
        // Run calculations for this activity
        const result = await autoSaveActivityCalculations(activity)
        
        if (result.success) {
          console.log(`âœ… Calculated values for activity: ${activity.activity_name}`)
        } else {
          console.warn(`âš ï¸ Calculation errors for activity ${activity.activity_name}:`, result.errors)
        }
        
        // Track project for later batch update
        if (activity.project_code) {
          processedProjects.add(activity.project_code)
        }
      } catch (error: any) {
        console.warn(`âš ï¸ Error processing activity:`, error)
        // Continue with next activity
      }
    }
    
    // Update project calculations for all affected projects
    console.log(`ğŸ”„ Updating calculations for ${processedProjects.size} projects...`)
    const projectCodes = Array.from(processedProjects)
    for (const projectCode of projectCodes) {
      try {
        await updateProjectCalculations(projectCode)
        console.log(`âœ… Updated calculations for project: ${projectCode}`)
      } catch (error: any) {
        console.warn(`âš ï¸ Error updating project ${projectCode}:`, error)
      }
    }
    
    console.log(`âœ… Completed calculations for ${importedData.length} BOQ activities`)
  } catch (error: any) {
    console.error('âŒ Error running BOQ calculations:', error)
    throw error
  }
}

/**
 * ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø¨Ø¹Ø¯ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Projects
 */
async function runCalculationsAfterProjectImport(importedData: any[]): Promise<void> {
  try {
    const { updateProjectCalculations } = await import('./autoCalculationSaver')
    
    console.log(`ğŸ“Š Processing ${importedData.length} imported projects for calculations...`)
    
    const processedProjects = new Set<string>()
    
    for (const row of importedData) {
      try {
        const projectCode = row['Project Code'] || row['project_code'] || row.project_code
        
        if (!projectCode) {
          console.warn('âš ï¸ Skipping project without Project Code:', row)
          continue
        }
        
        processedProjects.add(projectCode)
      } catch (error: any) {
        console.warn(`âš ï¸ Error processing project:`, error)
      }
    }
    
    // Update project calculations for all imported projects
    console.log(`ğŸ”„ Updating calculations for ${processedProjects.size} projects...`)
    const projectCodes = Array.from(processedProjects)
    for (const projectCode of projectCodes) {
      try {
        await updateProjectCalculations(projectCode)
        console.log(`âœ… Updated calculations for project: ${projectCode}`)
      } catch (error: any) {
        console.warn(`âš ï¸ Error updating project ${projectCode}:`, error)
      }
    }
    
    console.log(`âœ… Completed calculations for ${importedData.length} projects`)
  } catch (error: any) {
    console.error('âŒ Error running project calculations:', error)
    throw error
  }
}

/**
 * ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø¨Ø¹Ø¯ Ø§Ø³ØªÙŠØ±Ø§Ø¯ KPIs
 */
async function runCalculationsAfterKPIImport(importedData: any[]): Promise<void> {
  try {
    const supabase = getSupabaseClient()
    const { syncBOQFromKPI } = await import('./boqKpiSync')
    const { mapKPIFromDB } = await import('./dataMappers')
    
    console.log(`ğŸ“Š Processing ${importedData.length} imported KPIs for sync...`)
    
    const processedActivities = new Set<string>()
    
    for (const row of importedData) {
      try {
        // Check if row already has an ID (from insert with .select())
        let dbKPI = row
        
        // If no ID, fetch from database using Project Full Code and Activity Name
        if (!row.id) {
          const projectFullCode = row['Project Full Code'] || row['Project Code'] || row['project_full_code'] || row['project_code'] || ''
          const activityName = row['Activity Name'] || row['Activity'] || row['activity_name'] || row.activity_name || ''
          
          if (!projectFullCode || !activityName) {
            console.warn('âš ï¸ Skipping KPI without Project Full Code or Activity Name:', { projectFullCode, activityName })
            continue
          }
          
          // Fetch the KPI from database (now it has an ID)
          const { data: fetchedKPI, error: fetchError } = await supabase
            .from(TABLES.KPI)
            .select('*')
            .eq('Project Full Code', projectFullCode)
            .eq('Activity Name', activityName)
            .order('created_at', { ascending: false })
            .limit(1)
            .single()
          
          if (fetchError || !fetchedKPI) {
            console.warn(`âš ï¸ Could not fetch KPI ${activityName} for project ${projectFullCode}:`, fetchError)
            continue
          }
          
          dbKPI = fetchedKPI
        }
        
        // Map to application format
        const kpi = mapKPIFromDB(dbKPI)
        
        if (!kpi || !kpi.id) {
          console.warn('âš ï¸ Skipping KPI without ID:', dbKPI)
          continue
        }
        
        // Sync BOQ from KPI (syncBOQFromKPI takes projectCode and activityName)
        const syncResult = await syncBOQFromKPI(kpi.project_full_code, kpi.activity_name)
        
        if (syncResult.success) {
          console.log(`âœ… Synced BOQ for KPI: ${kpi.activity_name}`)
          
          // Track activity for later calculation
          const activityKey = `${kpi.project_full_code}-${kpi.activity_name}`
          processedActivities.add(activityKey)
        } else {
          console.warn(`âš ï¸ Sync failed for KPI ${kpi.activity_name}:`, syncResult.message)
        }
      } catch (error: any) {
        console.warn(`âš ï¸ Error processing KPI:`, error)
        // Continue with next KPI
      }
    }
    
    console.log(`âœ… Completed sync for ${importedData.length} KPIs`)
  } catch (error: any) {
    console.error('âŒ Error running KPI calculations:', error)
    throw error
  }
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ - Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ validation ÙˆØ§Ù„ØªØ±Ø§Ø¨Ø·
 */
export async function importTableData(
  tableName: string, 
  data: any[],
  mode: 'append' | 'replace' = 'append'
): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“¥ Importing ${data.length} rows to table: ${tableName} (mode: ${mode})`)
    console.log(`ğŸ”— Enhanced import with relationship validation`)
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­ÙˆÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø£ÙˆÙ„Ø§Ù‹
    const normalizedData = normalizeColumnNames(data, tableName)
    console.log(`âœ… Column names normalized for ${tableName}`)
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ±Ø§Ø¨Ø· Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
    const validation = await validateDataRelationships(tableName, normalizedData)
    
    if (!validation.valid) {
      console.error('âŒ Validation failed:', validation.errors)
      return {
        success: false,
        message: `Validation failed: ${validation.errors.join(', ')}`,
        error: validation.errors.join(', ')
      }
    }
    
    // Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª (Ù„ÙƒÙ† Ù„Ø§ Ù†Ù…Ù†Ø¹ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯)
    if (validation.warnings.length > 0) {
      console.warn('âš ï¸ Import warnings:', validation.warnings)
    }
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆØ¶Ø¹ "replace"ØŒ Ù†Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£ÙˆÙ„Ø§Ù‹
    if (mode === 'replace') {
      console.log('ğŸ—‘ï¸ Clearing existing data first...')
      const clearResult = await clearTableData(tableName)
      if (!clearResult.success) {
        return clearResult
      }
    }
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±Ø§Ø¨Ø·
    const cleanedData = normalizedData.map((row, index) => {
      const cleanedRow: any = {}
      
      Object.keys(row).forEach(key => {
        let value = row[key]
        
        // âš ï¸ Ù„Ø§ Ù†Ø­Ø°Ù Project Code, Project Full Code, Project Sub Code, Ø£Ùˆ Activity Name Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª ÙØ§Ø±ØºØ©
        // Ù‡Ø°Ù‡ Ø­Ù‚ÙˆÙ„ Ù…Ù‡Ù…Ø© Ù„Ù„ØªØ±Ø§Ø¨Ø·
        const isImportantField = 
          key === 'Project Code' || 
          key === 'Project Sub Code' ||
          key === 'Project Sub-Code' ||
          key === 'Project Full Code' ||
          key === 'Activity Name' ||
          key === 'Activity' ||
          key === 'Input Type' // Important for KPI table
        
        if (!isImportantField && (value === '' || value === 'null' || value === 'NULL' || value === null || value === undefined)) {
          cleanedRow[key] = null
          return
        }
        
        // âœ… Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Project Code Ùˆ Activity Name Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª strings ÙØ§Ø±ØºØ©
        if (isImportantField && (value === null || value === undefined)) {
          cleanedRow[key] = ''
          return
        }
        
        // âœ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø±Ù‚Ù…ÙŠØ©: ØªØ­ÙˆÙŠÙ„ "#N/A" Ø¥Ù„Ù‰ null ÙˆØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ numbers
        const isNumericField = key === 'Total Hours' || key === 'Cost'
        if (isNumericField) {
          // ØªÙ†Ø¸ÙŠÙ Ù‚ÙŠÙ… "#N/A" Ùˆ "N/A" - ØªØ­Ù‚Ù‚ Ø´Ø§Ù…Ù„
          const stringValue = String(value || '').trim().toUpperCase()
          if (stringValue === '#N/A' || stringValue === 'N/A' || stringValue === '' || stringValue === 'NULL' || stringValue === 'NULL' || stringValue.includes('#N/A') || stringValue.includes('N/A')) {
            cleanedRow[key] = null
            return
          }
          
          // ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ number - ØªÙ†Ø¸ÙŠÙ Ø´Ø§Ù…Ù„
          if (value !== null && value !== undefined && value !== '') {
            // Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ "#N/A" Ø£Ùˆ "N/A" Ù…Ù† Ø§Ù„Ù‚ÙŠÙ…Ø©
            let cleanValue = String(value).replace(/#N\/A/gi, '').replace(/N\/A/gi, '').trim()
            if (cleanValue === '' || cleanValue === 'null' || cleanValue === 'NULL') {
              cleanedRow[key] = null
              return
            }
            
            const numValue = typeof cleanValue === 'string' ? parseFloat(cleanValue.replace(/[^0-9.-]/g, '')) : Number(cleanValue)
            if (!isNaN(numValue) && isFinite(numValue)) {
              cleanedRow[key] = numValue
              return
            } else {
              cleanedRow[key] = null
              return
            }
          } else {
            cleanedRow[key] = null
            return
          }
        }
        
        // Handle different data types for non-numeric fields
        if (typeof value === 'string') {
          // Try to convert date strings
          if (key.toLowerCase().includes('date') || key.toLowerCase().includes('time')) {
            // Skip if it's clearly not a date (contains letters that shouldn't be in dates)
            if (/[a-zA-Z]{3,}/.test(value) && !value.match(/^\d{4}-\d{2}-\d{2}/)) {
              console.warn(`âš ï¸ Skipping invalid date value in row ${index + 1}, column ${key}: "${value}"`)
              cleanedRow[key] = null
              return
            }
          }
        }
        
        cleanedRow[key] = value
      })
      
      // Log first few cleaned rows for debugging
      if (index < 3) {
        console.log(`ğŸ“‹ Cleaned Row ${index + 1}:`, cleanedRow)
      }
      
      return cleanedRow
    })
    
    console.log(`ğŸ“‹ Data cleaned, importing ${cleanedData.length} rows...`)
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (chunks) Ù„ØªØ¬Ù†Ø¨ ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ù†Ø¸Ø§Ù…
    const CHUNK_SIZE = 1000 // Ø§Ø³ØªÙŠØ±Ø§Ø¯ 1000 ØµÙ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
    const totalChunks = Math.ceil(cleanedData.length / CHUNK_SIZE)
    let totalInserted = 0
    let totalErrors = 0
    
    // Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª
    for (let i = 0; i < cleanedData.length; i += CHUNK_SIZE) {
      const chunk = cleanedData.slice(i, i + CHUNK_SIZE)
      const chunkNumber = Math.floor(i / CHUNK_SIZE) + 1
      
      // âœ… ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ø¶Ø§ÙÙŠ: Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ "#N/A" Ù…ØªØ¨Ù‚ÙŠØ© Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
      const finalCleanedChunk = chunk.map(row => {
        const cleanedRow = { ...row }
        if (tableName === TABLES.MANPOWER) {
          // ØªÙ†Ø¸ÙŠÙ "Total Hours" Ùˆ "Cost"
          if ('Total Hours' in cleanedRow) {
            const totalHours = cleanedRow['Total Hours']
            if (typeof totalHours === 'string' && (totalHours.includes('#N/A') || totalHours.includes('N/A'))) {
              cleanedRow['Total Hours'] = null
            }
          }
          if ('Cost' in cleanedRow) {
            const cost = cleanedRow['Cost']
            if (typeof cost === 'string' && (cost.includes('#N/A') || cost.includes('N/A'))) {
              cleanedRow['Cost'] = null
            }
          }
        }
        return cleanedRow
      })
      
      console.log(`ğŸ“¦ Importing chunk ${chunkNumber}/${totalChunks} (${finalCleanedChunk.length} rows)...`)
      
      try {
        const { data: insertedData, error } = await supabase
          .from(tableName)
          .insert(finalCleanedChunk as any)
          .select()
        
        if (error) {
          console.error(`âŒ Error importing chunk ${chunkNumber}:`, error)
          totalErrors += chunk.length
          
          // Ø¥Ø°Ø§ ÙØ´Ù„ chunkØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù…Ø¹ batch Ø£ØµØºØ±
          if (finalCleanedChunk.length > 100) {
            console.log(`ğŸ”„ Retrying chunk ${chunkNumber} with smaller batches...`)
            const smallerChunkSize = 100
            for (let j = 0; j < finalCleanedChunk.length; j += smallerChunkSize) {
              const smallerChunk = finalCleanedChunk.slice(j, j + smallerChunkSize)
              
              // âœ… ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„Ù€ smaller chunks Ø£ÙŠØ¶Ø§Ù‹
              const finalSmallerChunk = smallerChunk.map(row => {
                const cleanedRow = { ...row }
                if (tableName === TABLES.MANPOWER) {
                  if ('Total Hours' in cleanedRow) {
                    const totalHours = cleanedRow['Total Hours']
                    if (typeof totalHours === 'string' && (totalHours.includes('#N/A') || totalHours.includes('N/A'))) {
                      cleanedRow['Total Hours'] = null
                    }
                  }
                  if ('Cost' in cleanedRow) {
                    const cost = cleanedRow['Cost']
                    if (typeof cost === 'string' && (cost.includes('#N/A') || cost.includes('N/A'))) {
                      cleanedRow['Cost'] = null
                    }
                  }
                }
                return cleanedRow
              })
              
              const { error: retryError } = await supabase
                .from(tableName)
                .insert(finalSmallerChunk as any)
              
              if (retryError) {
                console.error(`âŒ Error importing smaller chunk:`, retryError)
                totalErrors += smallerChunk.length
              } else {
                totalInserted += smallerChunk.length
              }
              
              // Ø¥Ø¹Ø·Ø§Ø¡ Ø§Ù„Ù…ØªØµÙØ­ ÙØ±ØµØ© Ù„Ù„ØªÙ†ÙØ³
              await new Promise(resolve => setTimeout(resolve, 50))
            }
          } else {
            totalErrors += chunk.length
          }
        } else {
          totalInserted += chunk.length
        }
        
        // Ø¥Ø¹Ø·Ø§Ø¡ Ø§Ù„Ù…ØªØµÙØ­ ÙØ±ØµØ© Ù„Ù„ØªÙ†ÙØ³ Ø¨ÙŠÙ† Ø§Ù„Ø¯ÙØ¹Ø§Øª
        if (i + CHUNK_SIZE < cleanedData.length) {
          await new Promise(resolve => setTimeout(resolve, 100))
        }
      } catch (chunkError: any) {
        console.error(`âŒ Error importing chunk ${chunkNumber}:`, chunkError)
        totalErrors += chunk.length
      }
    }
    
    if (totalErrors > 0) {
      console.error(`âŒ Error importing to ${tableName}: ${totalErrors} rows failed`)
      return {
        success: totalInserted > 0,
        message: `Imported ${totalInserted} rows successfully, ${totalErrors} rows failed`,
        error: `${totalErrors} rows failed to import`,
        affectedRows: totalInserted
      }
    }
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ (Ù…Ø«Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø© Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹)
    try {
      if (tableName === TABLES.BOQ_ACTIVITIES || tableName === 'Planning Database - BOQ Rates') {
        console.log('ğŸ”„ Running calculations for imported BOQ activities...')
        await runCalculationsAfterBOQImport(cleanedData.slice(0, 100)) // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹ÙŠÙ†Ø© ÙÙ‚Ø·
      } else if (tableName === TABLES.PROJECTS || tableName === 'Planning Database - ProjectsList') {
        console.log('ğŸ”„ Updating project calculations for imported projects...')
        await runCalculationsAfterProjectImport(cleanedData.slice(0, 100))
      } else if (tableName === TABLES.KPI || tableName === 'Planning Database - KPI') {
        console.log('ğŸ”„ Syncing KPIs with BOQ activities...')
        await runCalculationsAfterKPIImport(cleanedData.slice(0, 100))
      }
    } catch (calcError: any) {
      console.warn('âš ï¸ Calculations after import had errors (data still imported):', calcError)
      // Don't fail the import if calculations fail
    }
    
    // âœ… Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ù„ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª
    triggerGlobalRefresh(tableName)
    console.log(`ğŸ”„ Triggered global refresh for all pages`)
    
    // Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
    let successMessage = `Successfully imported ${totalInserted} rows`
    if (totalErrors > 0) {
      successMessage += ` (${totalErrors} rows failed)`
    }
    if (validation.warnings.length > 0) {
      successMessage += `\n\nWarnings:\n${validation.warnings.join('\n')}`
    }
    
    // âœ… Ø§Ù„Ù†Ø¬Ø§Ø­ - ØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    console.log(`âœ… Successfully imported ${totalInserted} rows to ${tableName}`)
    return {
      success: totalInserted > 0,
      message: successMessage,
      affectedRows: totalInserted,
      data: validation.warnings.length > 0 ? { warnings: validation.warnings } : undefined
    }
    
  } catch (error: any) {
    console.error(`âŒ Error importing to table ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to import data',
      error: error.message
    }
  }
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ (template) ÙØ§Ø±Øº Ù„Ù„Ø¬Ø¯ÙˆÙ„ - Ù…Ø­Ø³Ù† Ù…Ø¹ Templates Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
 */
export async function getTableTemplate(tableName: string): Promise<OperationResult> {
  try {
    console.log(`ğŸ“‹ Getting enhanced template for table: ${tableName}`)
    
    // Ø§Ø³ØªØ®Ø¯Ø§Ù… Templates Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
    const template = getEnhancedTemplate(tableName)
    
    if (!template) {
      console.error(`âŒ No enhanced template found for ${tableName}`)
      return {
        success: false,
        message: `No enhanced template available for ${tableName}`,
        error: 'Template not found'
      }
    }
    
    console.log(`âœ… Successfully generated enhanced template for ${tableName}`)
    return {
      success: true,
      message: 'Enhanced template generated successfully',
      data: template
    }
    
  } catch (error: any) {
    console.error(`âŒ Error getting template for ${tableName}:`, error)
    return {
      success: false,
      message: error.message || 'Failed to get template',
      error: error.message
    }
  }
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Template Ù…Ø­Ø³Ù† Ù„ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
 */
function getEnhancedTemplate(tableName: string): any | null {
  const templates: Record<string, any> = {
    // Activities Database Template
    'activities': {
      name: 'Activity Name',
      division: 'Division Name',
      unit: 'Unit',
      category: 'Category',
      description: 'Description',
      typical_duration: 1,
      is_active: true,
      usage_count: 0
    },
    
    // Divisions Template
    'divisions': {
      name: 'Division Name',
      description: 'Division Description',
      is_active: true
    },
    
    // Project Types Template
    'project_types': {
      name: 'Project Type Name',
      description: 'Project Type Description',
      is_active: true
    },
    
    // Currencies Template
    'currencies': {
      code: 'USD',
      name: 'Currency Name',
      symbol: '$',
      exchange_rate: 1.0,
      is_default: false,
      is_active: true
    },
    
    // Projects Template
    'Planning Database - ProjectsList': {
      'Project Code': 'P5066',
      'Project Sub-Code': 'I2',
      'Project Full Code': 'P5066-I2', // âœ… Added: Important for matching
      'Project Name': 'Sample Project Name',
      'Project Type': 'Construction',
      'Responsible Division': 'Enabling Division',
      'Plot Number': 'PLOT-001',
      'Contract Amount': '1000000',
      'Project Status': 'on-going',
      'KPI Completed': 'No',
      'Contract Status': 'Active',
      'Project Start Date': '2024-01-01',
      'Project Completion Date': '2024-12-31'
    },
    
    // BOQ Activities Template
    'Planning Database - BOQ Rates': {
      'Project Code': 'P5066',
      'Project Sub Code': 'I2',
      'Project Full Code': 'P5066-I2', // âœ… Added: Important for matching
      'Activity': 'Mobilization',
      'Activity Name': 'Mobilization',
      'Activity Division': 'Enabling Division',
      'Unit': 'Lump Sum',
      'Zone Ref': 'Zone 1',
      'Zone Number': '1',
      'Total Units': '1',
      'Planned Units': '1',
      'Rate': '50000',
      'Total Value': '50000',
      'Planned Activity Start Date': '2024-01-01',
      'Deadline': '2024-01-15',
      'Calendar Duration': '15'
    },
    
    // KPI Template
    'Planning Database - KPI': {
      'Project Full Code': 'P5066-I2', // âœ… Priority: Use Project Full Code
      'Project Code': 'P5066',
      'Project Sub Code': 'I2',
      'Activity Name': 'Mobilization',
      'Activity': 'Mobilization',
      'Input Type': 'Planned', // Required: 'Planned' or 'Actual'
      'Quantity': '1',
      'Unit': 'Lump Sum',
      'Section': 'General',
      'Zone': 'Zone 1',
      'Target Date': '2024-01-01',
      'Activity Date': '2024-01-01'
    },
    
    // Company Settings Template
    'company_settings': {
      setting_key: 'setting_key',
      setting_value: 'setting_value',
      setting_type: 'text',
      description: 'Setting Description'
    }
  }
  
  return templates[tableName] || null
}

/**
 * Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
 */
/**
 * ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
 */
export async function cleanupOldData(options: {
  kpiDaysOld?: number
  boqDaysOld?: number
  projectsDaysOld?: number
} = {}): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    const {
      kpiDaysOld = 180, // 6 Ø£Ø´Ù‡Ø±
      boqDaysOld = 365, // Ø³Ù†Ø©
      projectsDaysOld = 730 // Ø³Ù†ØªÙŠÙ†
    } = options

    console.log('ğŸ§¹ Starting data cleanup...')
    
    const results: any = {
      kpi: { deleted: 0, error: null },
      boq: { deleted: 0, error: null },
      projects: { deleted: 0, error: null }
    }

    // ØªÙ†Ø¸ÙŠÙ KPIs Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    if (kpiDaysOld > 0) {
      try {
        const cutoffDate = new Date()
        cutoffDate.setDate(cutoffDate.getDate() - kpiDaysOld)
        
        const { error: kpiError, count: kpiCount } = await supabase
          .from(TABLES.KPI)
          .delete({ count: 'exact' })
          .lt('created_at', cutoffDate.toISOString())
        
        if (kpiError) {
          console.error('âŒ Error cleaning KPI data:', kpiError)
          results.kpi.error = kpiError.message
        } else {
          results.kpi.deleted = kpiCount || 0
          console.log(`âœ… Cleaned ${kpiCount || 0} old KPI records`)
        }
      } catch (error: any) {
        results.kpi.error = error.message
      }
    }

    // ØªÙ†Ø¸ÙŠÙ BOQ Activities Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…ÙƒØªÙ…Ù„Ø©)
    if (boqDaysOld > 0) {
      try {
        const cutoffDate = new Date()
        cutoffDate.setDate(cutoffDate.getDate() - boqDaysOld)
        
        const { error: boqError, count: boqCount } = await supabase
          .from(TABLES.BOQ_ACTIVITIES)
          .delete({ count: 'exact' })
          .lt('created_at', cutoffDate.toISOString())
          .eq('Status', 'Completed') // ÙÙ‚Ø· Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©
        
        if (boqError) {
          console.error('âŒ Error cleaning BOQ data:', boqError)
          results.boq.error = boqError.message
        } else {
          results.boq.deleted = boqCount || 0
          console.log(`âœ… Cleaned ${boqCount || 0} old completed BOQ activities`)
        }
      } catch (error: any) {
        results.boq.error = error.message
      }
    }

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…ÙƒØªÙ…Ù„Ø©)
    if (projectsDaysOld > 0) {
      try {
        const cutoffDate = new Date()
        cutoffDate.setDate(cutoffDate.getDate() - projectsDaysOld)
        
        const { error: projectsError, count: projectsCount } = await supabase
          .from(TABLES.PROJECTS)
          .delete({ count: 'exact' })
          .lt('created_at', cutoffDate.toISOString())
          .in('Status', ['Completed', 'Cancelled']) // ÙÙ‚Ø· Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© Ø£Ùˆ Ø§Ù„Ù…Ù„ØºÙŠØ©
        
        if (projectsError) {
          console.error('âŒ Error cleaning Projects data:', projectsError)
          results.projects.error = projectsError.message
        } else {
          results.projects.deleted = projectsCount || 0
          console.log(`âœ… Cleaned ${projectsCount || 0} old completed/cancelled projects`)
        }
      } catch (error: any) {
        results.projects.error = error.message
      }
    }

    const totalDeleted = results.kpi.deleted + results.boq.deleted + results.projects.deleted
    const hasErrors = results.kpi.error || results.boq.error || results.projects.error

    console.log(`ğŸ§¹ Cleanup completed: ${totalDeleted} records deleted`)
    
    return {
      success: !hasErrors,
      message: hasErrors 
        ? `Cleanup completed with some errors. Deleted ${totalDeleted} records.`
        : `Successfully cleaned up ${totalDeleted} old records`,
      data: results,
      affectedRows: totalDeleted,
      error: hasErrors ? 'Some operations failed' : undefined
    }

  } catch (error: any) {
    console.error('âŒ Error during cleanup:', error)
    return {
      success: false,
      message: `Cleanup failed: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø·Ø§Ø¡ ØªÙˆØµÙŠØ§Øª
 */
export async function getDataSizeAnalysis(): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log('ğŸ“Š Analyzing data size...')
    
    const tables = getAllTables()
    const analysis: any = {}
    
    for (const table of tables) {
      const { count, error } = await supabase
        .from(table.name)
        .select('*', { count: 'exact', head: true })
      
      if (error) {
        console.error(`âŒ Error counting ${table.name}:`, error)
        continue
      }
      
      const estimatedSize = (count || 0) * 0.5 // ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ
      const sizeKB = estimatedSize < 1024 ? estimatedSize : estimatedSize / 1024
      const sizeMB = sizeKB < 1024 ? sizeKB : sizeKB / 1024
      
      analysis[table.name] = {
        displayName: table.displayName,
        totalRows: count || 0,
        estimatedSize: sizeMB < 1 ? `${sizeKB.toFixed(2)} KB` : `${sizeMB.toFixed(2)} MB`,
        recommendation: getRecommendation(count || 0, table.name)
      }
    }
    
    const totalRows = Object.values(analysis).reduce((sum: number, table: any) => sum + table.totalRows, 0)
    const needsCleanup = totalRows > 10000 // Ø£ÙƒØ«Ø± Ù…Ù† 10,000 Ø³Ø¬Ù„
    
    console.log(`ğŸ“Š Analysis complete: ${totalRows} total rows`)
    
    return {
      success: true,
      message: `Analysis complete. ${totalRows} total rows across all tables.`,
      data: {
        tables: analysis,
        totalRows,
        needsCleanup,
        recommendations: getOverallRecommendations(totalRows)
      }
    }
    
  } catch (error: any) {
    console.error('âŒ Error analyzing data size:', error)
    return {
      success: false,
      message: `Analysis failed: ${error.message}`,
      error: error.message
    }
  }
}

function getRecommendation(count: number, tableName: string): string {
  if (tableName.includes('KPI') && count > 5000) {
    return 'Consider cleaning KPI records older than 6 months'
  }
  if (tableName.includes('BOQ') && count > 3000) {
    return 'Consider cleaning completed BOQ activities older than 1 year'
  }
  if (tableName.includes('Projects') && count > 1000) {
    return 'Consider archiving completed projects older than 2 years'
  }
  if (count > 10000) {
    return 'Large dataset - consider data archiving'
  }
  return 'Size is acceptable'
}

function getOverallRecommendations(totalRows: number): string[] {
  const recommendations = []
  
  if (totalRows > 20000) {
    recommendations.push('Database is very large - consider immediate cleanup')
    recommendations.push('Archive old data to improve performance')
  } else if (totalRows > 10000) {
    recommendations.push('Database is large - consider cleanup')
    recommendations.push('Monitor performance and clean old data regularly')
  } else if (totalRows > 5000) {
    recommendations.push('Database size is moderate')
    recommendations.push('Consider periodic cleanup of old records')
  } else {
    recommendations.push('Database size is optimal')
    recommendations.push('Continue regular maintenance')
  }
  
  return recommendations
}

export async function canManageDatabase(): Promise<boolean> {
  try {
    const supabase = getSupabaseClient()
    
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ
    const { data: { user }, error: userError } = await supabase.auth.getUser()
    
    if (userError || !user) {
      return false
    }
    
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø¬Ø¯ÙˆÙ„ users
    const { data: appUser, error: appUserError } = await supabase
      .from('users')
      .select('role, permissions, custom_permissions_enabled')
      .eq('id', user.id)
      .single()
    
    if (appUserError || !appUser) {
      return false
    }
    
    // Admin Ù„Ø¯ÙŠÙ‡ ØµÙ„Ø§Ø­ÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹
    if ((appUser as any).role === 'admin') return true
    
    // ÙØ­Øµ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø®ØµØµØ©
    const userPermissions = (appUser as any)?.permissions || []
    return userPermissions.includes('database.manage')
    
  } catch (error) {
    console.error('Error checking database permissions:', error)
    return false
  }
}

/**
 * ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ…Ù„Ù JSON
 */
export function downloadAsJSON(data: any, filename: string): void {
  const json = JSON.stringify(data, null, 2)
  const blob = new Blob([json], { type: 'application/json' })
  const url = URL.createObjectURL(blob)
  
  const link = document.createElement('a')
  link.href = url
  link.download = `${filename}_${new Date().toISOString().split('T')[0]}.json`
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  
  URL.revokeObjectURL(url)
}

/**
 * ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ…Ù„Ù CSV
 */
export function downloadAsCSV(data: any[], filename: string): void {
  if (!data || data.length === 0) {
    console.warn('No data to export')
    return
  }
  
  // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
  const headers = Object.keys(data[0])
  
  // Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ CSV
  const csvRows = [
    headers.join(','), // Ø§Ù„Ø±Ø£Ø³
    ...data.map(row => 
      headers.map(header => {
        const value = row[header]
        // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ…Ø©
        const cleaned = value?.toString().replace(/"/g, '""') || ''
        return `"${cleaned}"`
      }).join(',')
    )
  ]
  
  const csv = csvRows.join('\n')
  const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' })
  const url = URL.createObjectURL(blob)
  
  const link = document.createElement('a')
  link.href = url
  link.download = `${filename}_${new Date().toISOString().split('T')[0]}.csv`
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  
  URL.revokeObjectURL(url)
}

/**
 * ØªØ­Ù…ÙŠÙ„ template CSV ÙØ§Ø±Øº Ù…Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© - Ù…Ø­Ø³Ù† Ù…Ø¹ Ø£Ù…Ø«Ù„Ø©
 */
export function downloadCSVTemplate(template: any, filename: string): void {
  const headers = Object.keys(template)
  
  // Ø¥Ù†Ø´Ø§Ø¡ Ø£Ù…Ø«Ù„Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙˆÙ„
  const examples = getTemplateExamples(filename)
  
  // Create template with headers and examples
  const csvRows = [
    headers.join(','), // Headers
    // Add example rows
    ...examples.map(example => 
      headers.map(header => {
        const value = example[header] || template[header]
        if (value === null || value === undefined) return ''
        
        // Add quotes if needed
        const stringValue = String(value)
        if (stringValue.includes(',') || stringValue.includes('"') || stringValue.includes('\n')) {
          return `"${stringValue.replace(/"/g, '""')}"`
        }
        return stringValue
      }).join(',')
    )
  ]
  
  const csv = csvRows.join('\n')
  const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' })
  const url = URL.createObjectURL(blob)
  
  const link = document.createElement('a')
  link.href = url
  link.download = `${filename}_template.csv`
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  
  URL.revokeObjectURL(url)
}

/**
 * Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù…Ø«Ù„Ø© Ù„Ù„Ù€ Templates
 */
function getTemplateExamples(filename: string): any[] {
  const examples: Record<string, any[]> = {
    'activities': [
      {
        name: 'Mobilization',
        division: 'Enabling Division',
        unit: 'Lump Sum',
        category: 'General',
        description: 'Mobilization activities',
        typical_duration: 1,
        is_active: true,
        usage_count: 0
      },
      {
        name: 'Vibro Compaction',
        division: 'Enabling Division',
        unit: 'No.',
        category: 'Soil Improvement',
        description: 'Vibro compaction work',
        typical_duration: 2,
        is_active: true,
        usage_count: 0
      }
    ],
    
    'divisions': [
      {
        name: 'Enabling Division',
        description: 'Main enabling works division',
        is_active: true
      },
      {
        name: 'Infrastructure Division',
        description: 'Infrastructure development division',
        is_active: true
      }
    ],
    
    'project_types': [
      {
        name: 'Construction',
        description: 'General construction projects',
        is_active: true
      },
      {
        name: 'Infrastructure',
        description: 'Infrastructure development projects',
        is_active: true
      }
    ],
    
    'currencies': [
      {
        code: 'USD',
        name: 'US Dollar',
        symbol: '$',
        exchange_rate: 1.0,
        is_default: true,
        is_active: true
      },
      {
        code: 'EUR',
        name: 'European Euro',
        symbol: 'â‚¬',
        exchange_rate: 0.85,
        is_default: false,
        is_active: true
      }
    ],
    
    'Planning Database - ProjectsList': [
      {
        'Project Code': 'P5066',
        'Project Sub-Code': 'I2',
        'Project Full Code': 'P5066-I2', // âœ… Added: Important for matching
        'Project Name': 'Sample Project 1',
        'Project Type': 'Construction',
        'Responsible Division': 'Enabling Division',
        'Plot Number': 'PLOT-001',
        'Contract Amount': '1000000',
        'Project Status': 'on-going',
        'KPI Completed': 'No',
        'Project Start Date': '2024-01-01',
        'Project Completion Date': '2024-12-31'
      },
      {
        'Project Code': 'P5067',
        'Project Sub-Code': 'I1',
        'Project Full Code': 'P5067-I1', // âœ… Added: Important for matching
        'Project Name': 'Sample Project 2',
        'Project Type': 'Infrastructure',
        'Responsible Division': 'Infrastructure Division',
        'Plot Number': 'PLOT-002',
        'Contract Amount': '2500000',
        'Project Status': 'on-going',
        'KPI Completed': 'No',
        'Project Start Date': '2024-02-01',
        'Project Completion Date': '2025-01-31'
      }
    ],
    
    'Planning Database - BOQ Rates': [
      {
        'Project Code': 'P5066',
        'Project Sub Code': 'I2',
        'Project Full Code': 'P5066-I2', // âœ… Added: Important for matching
        'Activity': 'Mobilization',
        'Activity Name': 'Mobilization',
        'Activity Division': 'Enabling Division',
        'Unit': 'Lump Sum',
        'Zone Ref': 'Zone 1',
        'Zone Number': '1',
        'Total Units': '1',
        'Planned Units': '1',
        'Rate': '50000',
        'Total Value': '50000',
        'Planned Activity Start Date': '2024-01-01',
        'Deadline': '2024-01-15',
        'Calendar Duration': '15'
      },
      {
        'Project Code': 'P5066',
        'Project Sub Code': 'I2',
        'Project Full Code': 'P5066-I2', // âœ… Same project, different activity
        'Activity': 'Vibro Compaction',
        'Activity Name': 'Vibro Compaction',
        'Activity Division': 'Enabling Division',
        'Unit': 'No.',
        'Zone Ref': 'Zone 1',
        'Zone Number': '1',
        'Total Units': '100',
        'Planned Units': '80',
        'Rate': '250',
        'Total Value': '20000',
        'Planned Activity Start Date': '2024-01-16',
        'Deadline': '2024-02-15',
        'Calendar Duration': '30'
      }
    ],
    
    'Planning Database - KPI': [
      {
        'Project Full Code': 'P5066-I2', // âœ… Priority: Use Project Full Code
        'Project Code': 'P5066',
        'Project Sub Code': 'I2',
        'Activity Name': 'Mobilization',
        'Activity': 'Mobilization',
        'Input Type': 'Planned', // Required: 'Planned' or 'Actual'
        'Quantity': '1',
        'Unit': 'Lump Sum',
        'Section': 'General',
        'Zone': 'Zone 1',
        'Target Date': '2024-01-01',
        'Activity Date': '2024-01-01'
      },
      {
        'Project Full Code': 'P5066-I2', // âœ… Same project and activity, different input type
        'Project Code': 'P5066',
        'Project Sub Code': 'I2',
        'Activity Name': 'Vibro Compaction',
        'Activity': 'Vibro Compaction',
        'Input Type': 'Actual', // Required: 'Planned' or 'Actual'
        'Quantity': '100',
        'Unit': 'No.',
        'Section': 'Soil Improvement',
        'Zone': 'Zone 1',
        'Actual Date': '2024-01-20',
        'Activity Date': '2024-01-20'
      }
    ],
    
    'company_settings': [
      {
        setting_key: 'company_name',
        setting_value: 'Your Company Name',
        setting_type: 'text',
        description: 'Company name setting'
      },
      {
        setting_key: 'default_currency',
        setting_value: 'USD',
        setting_type: 'text',
        description: 'Default currency code'
      }
    ]
  }
  
  return examples[filename] || []
}

/**
 * Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù JSON
 */
export function readJSONFile(file: File): Promise<any> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader()
    
    reader.onload = (e) => {
      try {
        const json = JSON.parse(e.target?.result as string)
        resolve(json)
      } catch (error) {
        reject(new Error('Invalid JSON file'))
      }
    }
    
    reader.onerror = () => reject(new Error('Failed to read file'))
    reader.readAsText(file)
  })
}

/**
 * Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV
 */
export function readCSVFile(file: File): Promise<any[]> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader()
    
    reader.onload = (e) => {
      try {
        const csv = e.target?.result as string
        
        // Improved CSV parser that handles commas in quoted fields
        const parseCSVLine = (line: string): string[] => {
          const result: string[] = []
          let current = ''
          let inQuotes = false
          
          for (let i = 0; i < line.length; i++) {
            const char = line[i]
            
            if (char === '"') {
              inQuotes = !inQuotes
            } else if (char === ',' && !inQuotes) {
              result.push(current.trim())
              current = ''
            } else {
              current += char
            }
          }
          
          result.push(current.trim())
          return result.map(field => field.replace(/^"|"$/g, ''))
        }
        
        const lines = csv.split('\n').filter(line => line.trim())
        
        if (lines.length < 2) {
          reject(new Error('CSV file is empty or invalid'))
          return
        }
        
        // Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø±Ø£Ø³
        const headers = parseCSVLine(lines[0])
        
        console.log('ğŸ“‹ CSV Headers:', headers)
        
        // Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        const data = lines.slice(1).map((line, index) => {
          const values = parseCSVLine(line)
          const row: any = {}
          
          headers.forEach((header, colIndex) => {
            let value = values[colIndex] || ''
            
            // Clean and validate data
            if (value === '' || value === 'null' || value === 'NULL') {
              row[header] = null
            } else {
              row[header] = value
            }
          })
          
          // Log first few rows for debugging
          if (index < 3) {
            console.log(`ğŸ“‹ Row ${index + 1}:`, row)
          }
          
          return row
        })
        
        console.log(`ğŸ“‹ Parsed ${data.length} rows from CSV`)
        resolve(data)
      } catch (error) {
        console.error('âŒ CSV parsing error:', error)
        reject(new Error(`Failed to parse CSV file: ${error instanceof Error ? error.message : 'Unknown error'}`))
      }
    }
    
    reader.onerror = () => reject(new Error('Failed to read file'))
    reader.readAsText(file, 'UTF-8')
  })
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¢Ù…Ù† Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª - ÙŠØ­Ù„ Ù…Ø´Ø§ÙƒÙ„ ID ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
 */
export async function importTableDataSafe(
  tableName: string, 
  data: any[],
  mode: 'append' | 'replace' = 'append'
): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ›¡ï¸ Safe importing ${data.length} rows to table: ${tableName} (mode: ${mode})`)
    
    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø²Ø§Ù„Ø© Ø­Ù‚ÙˆÙ„ ID
    const cleanedData = data.map((row, index) => {
      const cleanedRow: any = {}
      
      Object.keys(row).forEach(key => {
        let value = row[key]
        
        // ØªØ®Ø·ÙŠ Ø­Ù‚ÙˆÙ„ ID ÙˆØ§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø©
        if (key.toLowerCase().includes('id') && 
            (key === 'id' || key === 'uuid' || key === 'created_at' || key === 'updated_at')) {
          console.log(`ğŸ›¡ï¸ Skipping ID field: ${key}`)
          return
        }
        
        // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©
        if (value === '' || value === 'null' || value === 'NULL' || value === null || value === undefined) {
          cleanedRow[key] = null
          return
        }
        
        // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        if (typeof value === 'string') {
          // Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
          if (key.toLowerCase().includes('date') || key.toLowerCase().includes('time')) {
            if (/[a-zA-Z]{3,}/.test(value) && !value.match(/^\d{4}-\d{2}-\d{2}/)) {
              console.warn(`âš ï¸ Skipping invalid date value in row ${index + 1}, column ${key}: "${value}"`)
              cleanedRow[key] = null
              return
            }
          }
          
          // Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
          if (key.toLowerCase().includes('amount') || 
              key.toLowerCase().includes('rate') || 
              key.toLowerCase().includes('count') ||
              key.toLowerCase().includes('duration') ||
              key.toLowerCase().includes('percentage')) {
            const numValue = parseFloat(value)
            if (!isNaN(numValue)) {
              cleanedRow[key] = numValue
              return
            }
          }
          
          // Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Boolean
          if (key.toLowerCase().includes('active') || 
              key.toLowerCase().includes('enabled') ||
              key.toLowerCase().includes('completed')) {
            if (value.toLowerCase() === 'true' || value === '1') {
              cleanedRow[key] = true
              return
            } else if (value.toLowerCase() === 'false' || value === '0') {
              cleanedRow[key] = false
              return
            }
          }
        }
        
        cleanedRow[key] = value
      })
      
      return cleanedRow
    }).filter(row => Object.keys(row).length > 0) // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©
    
    console.log(`ğŸ›¡ï¸ Cleaned data: ${cleanedData.length} rows (removed ${data.length - cleanedData.length} empty rows)`)
    
    if (cleanedData.length === 0) {
      return {
        success: false,
        message: 'No valid data to import after cleaning'
      }
    }
    
    // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆØ¶Ø¹ "replace"ØŒ Ù†Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£ÙˆÙ„Ø§Ù‹
    if (mode === 'replace') {
      console.log('ğŸ—‘ï¸ Clearing existing data first...')
      const clearResult = await clearTableData(tableName)
      if (!clearResult.success) {
        return clearResult
      }
    }
    
    // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¢Ù…Ù†Ø© Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
    let result: OperationResult
    
    if (tableName === 'activities') {
      // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¢Ù…Ù†Ø© Ù„Ù„Ø£Ù†Ø´Ø·Ø©
      result = await importActivitiesSafe(cleanedData)
    } else if (tableName === 'divisions') {
      // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¢Ù…Ù†Ø© Ù„Ù„Ø£Ù‚Ø³Ø§Ù…
      result = await importDivisionsSafe(cleanedData)
    } else if (tableName === 'project_types') {
      // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¢Ù…Ù†Ø© Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹
      result = await importProjectTypesSafe(cleanedData)
    } else if (tableName === 'currencies') {
      // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¢Ù…Ù†Ø© Ù„Ù„Ø¹Ù…Ù„Ø§Øª
      result = await importCurrenciesSafe(cleanedData)
    } else {
      // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø®Ø±Ù‰
      result = await importTableData(tableName, cleanedData, mode)
    }
    
    if (result.success) {
      console.log(`âœ… Safe import successful: ${result.message}`)
    } else {
      console.error(`âŒ Safe import failed: ${result.message}`)
    }
    
    return result
    
  } catch (error: any) {
    console.error('âŒ Safe import error:', error)
    return {
      success: false,
      message: `Safe import failed: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¢Ù…Ù† Ù„Ù„Ø£Ù†Ø´Ø·Ø©
 */
async function importActivitiesSafe(data: any[]): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ¯ Safe importing ${data.length} activities`)
    
    const results = []
    let successCount = 0
    let errorCount = 0
    const errors: string[] = []
    
    for (let i = 0; i < data.length; i++) {
      const row = data[i]
      
      try {
        // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        if (!row.name || !row.division || !row.unit) {
          errors.push(`Row ${i + 1}: Missing required fields (name, division, unit)`)
          errorCount++
          continue
        }
        
        // Ø¥Ø¯Ø±Ø§Ø¬ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø´Ø§Ø·
        const { data: result, error } = await supabase
          .from('activities')
          .upsert({
            name: row.name.trim(),
            division: row.division.trim(),
            unit: row.unit.trim(),
            category: row.category || null,
            description: row.description || null,
            typical_duration: row.typical_duration || null,
            is_active: row.is_active !== undefined ? row.is_active : true,
            usage_count: row.usage_count || 0,
            updated_at: new Date().toISOString()
          } as any, {
            onConflict: 'name,division'
          })
        
        if (error) {
          errors.push(`Row ${i + 1}: ${error.message}`)
          errorCount++
        } else {
          successCount++
        }
        
      } catch (error: any) {
        errors.push(`Row ${i + 1}: ${error.message}`)
        errorCount++
      }
    }
    
    return {
      success: errorCount === 0,
      message: `Imported ${successCount} activities${errorCount > 0 ? ` with ${errorCount} errors` : ''}`,
      affectedRows: successCount,
      error: errorCount > 0 ? errors.join('; ') : undefined
    }
    
  } catch (error: any) {
    return {
      success: false,
      message: `Activities import failed: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¢Ù…Ù† Ù„Ù„Ø£Ù‚Ø³Ø§Ù…
 */
async function importDivisionsSafe(data: any[]): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ¢ Safe importing ${data.length} divisions`)
    
    let successCount = 0
    let errorCount = 0
    const errors: string[] = []
    
    for (let i = 0; i < data.length; i++) {
      const row = data[i]
      
      try {
        if (!row.name) {
          errors.push(`Row ${i + 1}: Missing required field (name)`)
          errorCount++
          continue
        }
        
        const { error } = await supabase
          .from('divisions')
          .upsert({
            name: row.name.trim(),
            description: row.description || null,
            is_active: row.is_active !== undefined ? row.is_active : true,
            updated_at: new Date().toISOString()
          } as any, {
            onConflict: 'name'
          })
        
        if (error) {
          errors.push(`Row ${i + 1}: ${error.message}`)
          errorCount++
        } else {
          successCount++
        }
        
      } catch (error: any) {
        errors.push(`Row ${i + 1}: ${error.message}`)
        errorCount++
      }
    }
    
    return {
      success: errorCount === 0,
      message: `Imported ${successCount} divisions${errorCount > 0 ? ` with ${errorCount} errors` : ''}`,
      affectedRows: successCount,
      error: errorCount > 0 ? errors.join('; ') : undefined
    }
    
  } catch (error: any) {
    return {
      success: false,
      message: `Divisions import failed: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¢Ù…Ù† Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹
 */
async function importProjectTypesSafe(data: any[]): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ“ Safe importing ${data.length} project types`)
    
    let successCount = 0
    let errorCount = 0
    const errors: string[] = []
    
    for (let i = 0; i < data.length; i++) {
      const row = data[i]
      
      try {
        if (!row.name) {
          errors.push(`Row ${i + 1}: Missing required field (name)`)
          errorCount++
          continue
        }
        
        const { error } = await supabase
          .from('project_types')
          .upsert({
            name: row.name.trim(),
            description: row.description || null,
            is_active: row.is_active !== undefined ? row.is_active : true,
            updated_at: new Date().toISOString()
          } as any, {
            onConflict: 'name'
          })
        
        if (error) {
          errors.push(`Row ${i + 1}: ${error.message}`)
          errorCount++
        } else {
          successCount++
        }
        
      } catch (error: any) {
        errors.push(`Row ${i + 1}: ${error.message}`)
        errorCount++
      }
    }
    
    return {
      success: errorCount === 0,
      message: `Imported ${successCount} project types${errorCount > 0 ? ` with ${errorCount} errors` : ''}`,
      affectedRows: successCount,
      error: errorCount > 0 ? errors.join('; ') : undefined
    }
    
  } catch (error: any) {
    return {
      success: false,
      message: `Project types import failed: ${error.message}`,
      error: error.message
    }
  }
}

/**
 * Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¢Ù…Ù† Ù„Ù„Ø¹Ù…Ù„Ø§Øª
 */
async function importCurrenciesSafe(data: any[]): Promise<OperationResult> {
  try {
    const supabase = getSupabaseClient()
    
    console.log(`ğŸ’° Safe importing ${data.length} currencies`)
    
    let successCount = 0
    let errorCount = 0
    const errors: string[] = []
    
    // Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù…Ù„Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©ØŒ Ø³ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ ÙÙŠ upsert
    // Ø§Ù„Ù†Ø¸Ø§Ù… Ø³ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹ is_default ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙÙŠ upsert
    // ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Database/currency_default_management.sql Ù„Ø¥Ø¯Ø§Ø±Ø© Ø£ÙØ¶Ù„
    
    for (let i = 0; i < data.length; i++) {
      const row = data[i]
      
      try {
        if (!row.code || !row.name) {
          errors.push(`Row ${i + 1}: Missing required fields (code, name)`)
          errorCount++
          continue
        }
        
        const { error } = await supabase
          .from('currencies')
          .upsert({
            code: row.code.trim().toUpperCase(),
            name: row.name.trim(),
            symbol: row.symbol || null,
            exchange_rate: row.exchange_rate || 1,
            is_default: row.is_default === true || row.is_default === 'true',
            is_active: row.is_active !== undefined ? row.is_active : true,
            updated_at: new Date().toISOString()
          } as any, {
            onConflict: 'code'
          })
        
        if (error) {
          errors.push(`Row ${i + 1}: ${error.message}`)
          errorCount++
        } else {
          successCount++
        }
        
      } catch (error: any) {
        errors.push(`Row ${i + 1}: ${error.message}`)
        errorCount++
      }
    }
    
    return {
      success: errorCount === 0,
      message: `Imported ${successCount} currencies${errorCount > 0 ? ` with ${errorCount} errors` : ''}`,
      affectedRows: successCount,
      error: errorCount > 0 ? errors.join('; ') : undefined
    }
    
  } catch (error: any) {
    return {
      success: false,
      message: `Currencies import failed: ${error.message}`,
      error: error.message
    }
  }
}

